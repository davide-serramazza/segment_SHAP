{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:35.368184Z",
     "start_time": "2024-08-23T10:15:34.342597Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "#import torch.cuda\n",
    "import timeit\n",
    "import pandas as pd\n",
    "#import argparse\n",
    "import itertools\n",
    "from load_data import load_data # segment_SHAP\n",
    "from evaluation.metrics.entropy import Entropy_metric\n",
    "from models.predictor_utils import load_predictor\n",
    "from pickle import dump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:35.373483Z",
     "start_time": "2024-08-23T10:15:35.371673Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS\n",
    "datasets_folder_path = None\n",
    "attributions_folder_path = None\n",
    "trained_models_folder_path = None\n",
    "save_results_folder_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:43.829274Z",
     "start_time": "2024-08-23T10:15:43.826547Z"
    }
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "dataset_names = ['UWAVE', \"KeplerLightCurves\", \"MP8\", \"gunpoint\", \"EOG\"]    #[sys.argv[1]] # ['UWAVE', \"KeplerLightCurves\", \"MP8\", \"gunpoint\", \"EOG\"] \n",
    "predictor_names = ['resNet']    #[sys.argv[2]] [\"randomForest\", 'miniRocket', 'resNet', \"QUANT\"]\n",
    "segmentation_names = [\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"] # [\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"] \n",
    "background_names =  [\"average\"] #[\"average\", \"zero\", \"sampling\"]\n",
    "normalization_names = [\"default\"] #[\"default\", \"normalized\"]\n",
    "\n",
    "metric_names = [\"entropy\"]\n",
    "\n",
    "results_prefix = \"entropy\" #\"evaluation\"\n",
    "\n",
    "demo_mode = False\n",
    "demo_mode_samples = 25\n",
    "# demo\n",
    "if demo_mode:\n",
    "    dataset_names = ['UWAVE']\n",
    "    predictor_names = ['resNet'] #['randomForest', 'resNet', 'miniRocket']\n",
    "    segmentation_names = ['nnsegment']\n",
    "    background_names = [\"average\"]#, 'zero','sampling']\n",
    "    normalization_names = [\"default\", \"normalized\"]\n",
    "\n",
    "# optional\n",
    "# # get infos about which explanations are evaluated\n",
    "# datasets = list( explanations['attributions'].keys() )\n",
    "# segmentations = list( explanations['attributions'][datasets[0]].keys() )\n",
    "# predictors = list( explanations['attributions'][datasets[0]][segmentations[0]].keys() )\n",
    "# backgrounds = list( explanations['attributions'][datasets[0]][segmentations[0]][predictors[0]].keys() )\n",
    "# result_types = ['default','normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:44.413374Z",
     "start_time": "2024-08-23T10:15:44.410522Z"
    }
   },
   "outputs": [],
   "source": [
    "# column_names = ['Dataset', 'Segmentation', 'ML model', 'Background', 'Normalization', 'Metric', 'Perturb', \"Result\"]\n",
    "# df = pd.DataFrame(data=data_list, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:44.579741Z",
     "start_time": "2024-08-23T10:15:44.576671Z"
    }
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:15:47.048165Z",
     "start_time": "2024-08-23T10:15:45.314377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  UWAVE\n",
      "Predictor:  resNet\n",
      "assessing ('clasp', 'average', 'default', 'entropy')\n",
      "elapsed time 0.7922153000254184\n",
      "assessing ('greedygaussian', 'average', 'default', 'entropy')\n",
      "elapsed time 1.4598321998491883\n",
      "assessing ('equal', 'average', 'default', 'entropy')\n",
      "elapsed time 2.023792899912223\n",
      "assessing ('infogain', 'average', 'default', 'entropy')\n",
      "elapsed time 2.5859144998248667\n",
      "assessing ('nnsegment', 'average', 'default', 'entropy')\n",
      "elapsed time 3.160228200023994\n",
      "Dataset:  KeplerLightCurves\n",
      "Predictor:  resNet\n",
      "assessing ('clasp', 'average', 'default', 'entropy')\n",
      "elapsed time 6.795402699848637\n",
      "assessing ('greedygaussian', 'average', 'default', 'entropy')\n",
      "elapsed time 6.993549600010738\n",
      "assessing ('equal', 'average', 'default', 'entropy')\n",
      "elapsed time 7.18594739981927\n",
      "assessing ('infogain', 'average', 'default', 'entropy')\n",
      "elapsed time 7.390084099955857\n",
      "assessing ('nnsegment', 'average', 'default', 'entropy')\n",
      "elapsed time 7.559507600031793\n",
      "Dataset:  MP8\n",
      "Predictor:  resNet\n",
      "assessing ('clasp', 'average', 'default', 'entropy')\n",
      "elapsed time 9.785362900001928\n",
      "assessing ('greedygaussian', 'average', 'default', 'entropy')\n",
      "elapsed time 11.776724899886176\n",
      "assessing ('equal', 'average', 'default', 'entropy')\n",
      "elapsed time 13.805010200012475\n",
      "assessing ('infogain', 'average', 'default', 'entropy')\n",
      "elapsed time 15.876041099894792\n",
      "assessing ('nnsegment', 'average', 'default', 'entropy')\n",
      "elapsed time 17.84515619999729\n",
      "Dataset:  gunpoint\n",
      "Predictor:  resNet\n",
      "assessing ('clasp', 'average', 'default', 'entropy')\n",
      "elapsed time 18.00135020003654\n",
      "assessing ('greedygaussian', 'average', 'default', 'entropy')\n",
      "elapsed time 18.068364499835297\n",
      "assessing ('equal', 'average', 'default', 'entropy')\n",
      "elapsed time 18.141509999986738\n",
      "assessing ('infogain', 'average', 'default', 'entropy')\n",
      "elapsed time 18.212789800018072\n",
      "assessing ('nnsegment', 'average', 'default', 'entropy')\n",
      "elapsed time 18.27544380002655\n",
      "Dataset:  EOG\n",
      "Predictor:  resNet\n",
      "assessing ('clasp', 'average', 'default', 'entropy')\n",
      "elapsed time 19.417240399867296\n",
      "assessing ('greedygaussian', 'average', 'default', 'entropy')\n",
      "elapsed time 19.832645199960098\n",
      "assessing ('equal', 'average', 'default', 'entropy')\n",
      "elapsed time 20.172871599905193\n",
      "assessing ('infogain', 'average', 'default', 'entropy')\n",
      "elapsed time 20.494986899895594\n",
      "assessing ('nnsegment', 'average', 'default', 'entropy')\n",
      "elapsed time 20.844316700007766\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "if datasets_folder_path is None:\n",
    "    datasets_folder_path = \"datasets\" #os.path.join(cwd, \"datasets\")\n",
    "if attributions_folder_path is None:\n",
    "    attributions_folder_path = \"attributions\"\n",
    "if trained_models_folder_path is None:\n",
    "    trained_models_folder_path = \"trained_models\"\n",
    "if save_results_folder_path is None:\n",
    "    save_results_folder_path = os.path.join(\"evaluation\", \"entropy_results\")\n",
    "\n",
    "# device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "starttime = timeit.default_timer()\n",
    "\n",
    "eval_metrics = dict.fromkeys(metric_names)\n",
    "for key in eval_metrics:\n",
    "    if key==\"entropy\":\n",
    "         eval_metrics[key] = Entropy_metric()\n",
    "    else:\n",
    "        raise KeyError(f\"key {key} has no corresponding eval metric defined\")\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(\"Dataset: \", dataset_name)\n",
    "    # loading dataset\n",
    "    X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name, path=datasets_folder_path)\n",
    "    if demo_mode:\n",
    "        X_test, y_test = X_test[:demo_mode_samples], y_test[:demo_mode_samples]\n",
    "\n",
    "    for eval_metric in eval_metrics.values():\n",
    "        eval_metric.fit_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    for predictor_name in predictor_names:\n",
    "        print(\"Predictor: \", predictor_name)\n",
    "\n",
    "        # load classifier\n",
    "        predictor = load_predictor(path=trained_models_folder_path, predictor_name=predictor_name, dataset_name=dataset_name, device=device) # torch.device(device)\n",
    "\n",
    "        # load explanations\n",
    "        attribution_filename = \"_\".join((\"all_results\", dataset_name, predictor_name)) + \".npy\"\n",
    "        explanations = np.load(os.path.join(attributions_folder_path, attribution_filename), allow_pickle=True).item() # FileNotFoundError\n",
    "        label_mapping = explanations['label_mapping'][dataset_name]\n",
    "\n",
    "        for eval_metric in eval_metrics.values():\n",
    "            eval_metric.fit_ml_model(predictor)\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        for key in itertools.product(segmentation_names, background_names, normalization_names, metric_names):\n",
    "            segmentation_name, background_name, normalization_name, metric_name = key\n",
    "            print(\"assessing\", key)\n",
    "\n",
    "            # load model and explanations to access\n",
    "            attributions = explanations['attributions'][dataset_name][segmentation_name][predictor_name][background_name][normalization_name]\n",
    "            y_test_pred = explanations['y_test_pred'][dataset_name][predictor_name]\n",
    "            segments = explanations['segments'][dataset_name][segmentation_name]\n",
    "\n",
    "            eval_metric = eval_metrics[metric_name]\n",
    "            results = eval_metric.evaluate(segments)\n",
    "\n",
    "            for result_tuple in results:\n",
    "                data_list.append((dataset_name, segmentation_name, predictor_name, background_name, normalization_name, metric_name) + result_tuple)\n",
    "\n",
    "            print(\"elapsed time\", (timeit.default_timer() - starttime))\n",
    "\n",
    "        # save\n",
    "        column_names = ['Dataset', 'Segmentation', 'ML model', 'Background', 'Normalization', 'Metric', 'Perturb', \"Result\"]\n",
    "        df = pd.DataFrame(data=data_list, columns = column_names)\n",
    "        file_name = \"_\".join((results_prefix, predictor_name, dataset_name))\n",
    "        result_path = os.path.join(save_results_folder_path, file_name)\n",
    "        if not demo_mode:\n",
    "            df.to_csv(result_path)\n",
    "            # with open( \"_\".join( (dataset_name,classifier_name)) ,\"wb\") as f:\n",
    "            #     pickle.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>ML model</th>\n",
       "      <th>Background</th>\n",
       "      <th>Normalization</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Perturb</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EOG</td>\n",
       "      <td>clasp</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.704625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOG</td>\n",
       "      <td>clasp</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>std</td>\n",
       "      <td>0.235510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EOG</td>\n",
       "      <td>greedygaussian</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.908797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EOG</td>\n",
       "      <td>greedygaussian</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>std</td>\n",
       "      <td>0.056299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EOG</td>\n",
       "      <td>equal</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EOG</td>\n",
       "      <td>equal</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EOG</td>\n",
       "      <td>infogain</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.801382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOG</td>\n",
       "      <td>infogain</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>std</td>\n",
       "      <td>0.119031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EOG</td>\n",
       "      <td>nnsegment</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.963650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EOG</td>\n",
       "      <td>nnsegment</td>\n",
       "      <td>resNet</td>\n",
       "      <td>average</td>\n",
       "      <td>default</td>\n",
       "      <td>entropy</td>\n",
       "      <td>std</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset    Segmentation ML model Background Normalization   Metric Perturb  \\\n",
       "0     EOG           clasp   resNet    average       default  entropy    mean   \n",
       "1     EOG           clasp   resNet    average       default  entropy     std   \n",
       "2     EOG  greedygaussian   resNet    average       default  entropy    mean   \n",
       "3     EOG  greedygaussian   resNet    average       default  entropy     std   \n",
       "4     EOG           equal   resNet    average       default  entropy    mean   \n",
       "5     EOG           equal   resNet    average       default  entropy     std   \n",
       "6     EOG        infogain   resNet    average       default  entropy    mean   \n",
       "7     EOG        infogain   resNet    average       default  entropy     std   \n",
       "8     EOG       nnsegment   resNet    average       default  entropy    mean   \n",
       "9     EOG       nnsegment   resNet    average       default  entropy     std   \n",
       "\n",
       "     Result  \n",
       "0  0.704625  \n",
       "1  0.235510  \n",
       "2  0.908797  \n",
       "3  0.056299  \n",
       "4  1.000000  \n",
       "5  0.000000  \n",
       "6  0.801382  \n",
       "7  0.119031  \n",
       "8  0.963650  \n",
       "9  0.016639  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
