{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:15:30.875056Z",
     "start_time": "2024-06-11T13:15:28.970829Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import ShapleyValueSampling\n",
    "from tqdm import trange\n",
    "\n",
    "from load_data import load_data\n",
    "from train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:15:30.878755Z",
     "start_time": "2024-06-11T13:15:30.875889Z"
    }
   },
   "source": [
    "# to utils.py\n",
    "\n",
    "def change_points_to_lengths(change_points, array_length):\n",
    "\t# change points is 1D iterable of idxs\n",
    "\t# assumes that each change point is the start of a new segment, aka change_points = start points\n",
    "\tstart_points = np.array(change_points)\n",
    "\tend_points = np.append(change_points, array_length)[1:]\n",
    "\tlengths = end_points - start_points\n",
    "\treturn lengths\n",
    "\n",
    "def lengths_to_weights(lengths):\n",
    "\t# lengths is 1D iterable of positive ints\n",
    "\tstart_idx = 0\n",
    "\tend_idx = 0\n",
    "\tsegment_weights = 1 / lengths\n",
    "\tweights = np.ones(lengths.sum())\n",
    "\tfor segment_weight, length in zip(segment_weights, lengths):\n",
    "\t\tend_idx += length\n",
    "\t\tweights[start_idx: end_idx] = segment_weight\n",
    "\t\tstart_idx = end_idx\n",
    "\treturn weights\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:15:31.038984Z",
     "start_time": "2024-06-11T13:15:30.879605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\"\n",
    "\n",
    "# dictionary mapping predictors to torch vs other, necessary for Captum \n",
    "predictors = {\n",
    "\t'torch' : ['resNet'],\n",
    "\t'scikit' : ['miniRocket','randomForest']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:15:33.100038Z",
     "start_time": "2024-06-11T13:15:31.039584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data\n",
    "dataset_name = 'gunpoint'\n",
    "predictor_name = 'resNet'\n",
    "\n",
    "# I've returned also a Label encoder from load_data to have a mapping between dataset label\n",
    "# which can be string while captum requires idx (integers)\n",
    "X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "\n",
    "# train model\n",
    "if predictor_name=='resNet':\n",
    "\tclf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "elif predictor_name=='miniRocket':\n",
    "\tclf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "\n",
    "# create a dictionary to be dumped containing attribution and metadata\n",
    "# initialize data structure meant to contain the segments\n",
    "segments =  np.empty( (X_test.shape[0] , X_test.shape[1]), dtype=object) if X_test.shape[1] > 1  else (\n",
    "\tnp.empty( X_test.shape[0] , dtype=object))\n",
    "\n",
    "results = {\n",
    "\t'attributions' : {},\n",
    "\t'segments' : segments,\n",
    "\t'y_test_true' : y_test,\n",
    "\t'y_test_pred' : preds,\n",
    "\t'label_mapping' : enc,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ResNet\n",
      "Epoch 1: train loss:  0.673, \t train accuracy  0.540 \n",
      "          test loss:  0.583,  \t test accuracy  0.787\n",
      "Epoch 11: train loss:  0.267, \t train accuracy  0.900 \n",
      "          test loss:  0.323,  \t test accuracy  0.913\n",
      "Epoch 21: train loss:  0.119, \t train accuracy  1.000 \n",
      "          test loss:  0.168,  \t test accuracy  1.000\n",
      "Epoch 31: train loss:  0.098, \t train accuracy  1.000 \n",
      "          test loss:  0.116,  \t test accuracy  1.000\n",
      "Epoch 41: train loss:  0.052, \t train accuracy  1.000 \n",
      "          test loss:  0.093,  \t test accuracy  1.000\n",
      "training early stopped! Final stats are:\n",
      "Epoch 51: train loss:  0.049, \t train accuracy  1.000 \n",
      "          test loss:  0.078,  \t test accuracy  1.000\n",
      "accuracy for resNet is  1.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:15:36.643230Z",
     "start_time": "2024-06-11T13:15:36.637010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_background = 50\n",
    "background_types = [\"average\", \"zero\",\"sampling\"] # zero, constant, average, multisample\n",
    "for type in background_types:\n",
    "\tresults['attributions'][type] = np.zeros( X_test.shape ,dtype=np.float32 )"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:17:55.447739Z",
     "start_time": "2024-06-11T13:15:42.509102Z"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "\tSHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "\n",
    "\tfor i in trange ( X_test.shape[0] ) : #\n",
    "\n",
    "\t\t# get current sample and label\n",
    "\t\tts, y = X_test[i] , torch.tensor( y_test[i:i+1] )\n",
    "\n",
    "\t\t# get segment and its tensor representation\n",
    "\t\tcurrent_segments = get_claSP_segmentation(ts)[:X_test.shape[1]]\n",
    "\t\tresults['segments'][i] = current_segments\n",
    "\t\tmask = get_feature_mask(current_segments,ts.shape[-1])\n",
    "\n",
    "\t\tts = torch.tensor(ts).repeat(1,1,1)\n",
    "\n",
    "\t\tfor background_type in background_types:\n",
    "\n",
    "\n",
    "\t\t\t# background data\n",
    "\t\t\tif background_type==\"zero\":\n",
    "\t\t\t\tbackground_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "\t\t\telif background_type==\"sampling\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background)\n",
    "\t\t\telif background_type==\"average\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "\n",
    "\t\t\tts = ts.repeat(background_dataset.shape[0],1,1) if background_type==\"sampling\" else ts\n",
    "\n",
    "\t\t\t# data structure with room for each sample in the background dataset\n",
    "\t\t\tif predictor_name in predictors['scikit']:\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\t\t\telif predictor_name in predictors['torch']:\n",
    "\t\t\t\tts = ts.to(device); y = y.to(device)\n",
    "\t\t\t\tmask = mask.to(device) ; background_dataset =  background_dataset.to(device)\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset)\n",
    "\t\t\t\t########  only for random forest as every instance should be a 1D tensor    ########\n",
    "\t\t\t\t#current_attr[j:j+actual_size] = tmp.reshape(actual_size,X_test.shape[1],X_test.shape[2])\n",
    "\t\t\t\t###############################################################################\n",
    "\n",
    "\t\t\t# compute as final explanation mean of each explanation using a different baseline\n",
    "\t\t\tresults['attributions'][background_type][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "\t\t\t\tbackground_type==\"sampling\" else tmp[0].cpu().numpy()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:12<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:18:03.303966Z",
     "start_time": "2024-06-11T13:18:03.292514Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # normalized weights\n",
    "weights = np.array(list(map(lambda x: list(map(lambda y: lengths_to_weights(change_points_to_lengths(y, X_train.shape[-1])), x)), results[\"segments\"])))\n",
    "results[\"attributions\"][background_type] *= weights"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:18:04.558222Z",
     "start_time": "2024-06-11T13:18:04.550714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dump result to disk\n",
    "file_name = \"_\".join ( (predictor_name,dataset_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:18:05.857005Z",
     "start_time": "2024-06-11T13:18:05.847206Z"
    }
   },
   "source": "results['attributions'][background_type].sum(axis=(1,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00771312,  0.03489595,  0.08431351, -0.04803198,  0.00195293,\n",
       "        0.06863715,  0.00032749,  0.06003411,  0.01224429,  0.03213294,\n",
       "        0.00200376, -0.00859401,  0.08302087, -0.00203428, -0.01158601,\n",
       "        0.00246663,  0.02346536,  0.04300815,  0.04242647,  0.06092416,\n",
       "       -0.00733136,  0.08475581,  0.02149864,  0.00419958, -0.0500086 ,\n",
       "        0.00815944, -0.02794795, -0.03676845, -0.01178761, -0.00268818,\n",
       "        0.00474527,  0.05431886,  0.03923873,  0.02237679, -0.00610698,\n",
       "        0.00618449,  0.01734989,  0.00603125, -0.01472872,  0.03765767,\n",
       "       -0.00510494,  0.0699935 ,  0.02377506,  0.00785602,  0.00218885,\n",
       "       -0.01827871,  0.05209655,  0.02040819,  0.00573549,  0.03228654,\n",
       "        0.01540048,  0.04855904,  0.02197419,  0.06047125,  0.03856869,\n",
       "       -0.01358054,  0.01103381,  0.01240072,  0.00826397,  0.00489563,\n",
       "       -0.02412014,  0.09228799,  0.00876795, -0.01159254,  0.02882524,\n",
       "        0.0091797 , -0.04600435,  0.00671154, -0.00639732,  0.05243688,\n",
       "       -0.00560739, -0.02527353,  0.0129237 ,  0.02895765,  0.06932159,\n",
       "        0.01174057,  0.03959325,  0.09819697,  0.05474555,  0.0254807 ,\n",
       "        0.02297652,  0.00337929,  0.07193799,  0.01118315, -0.01360822,\n",
       "        0.02933268, -0.02532789,  0.040232  ,  0.02470204,  0.01547587,\n",
       "        0.02391295,  0.06302223,  0.02510513,  0.09348466, -0.0143663 ,\n",
       "        0.02163274,  0.01680212, -0.00173985, -0.02773001, -0.00615743,\n",
       "        0.06366177, -0.01190054, -0.01423861,  0.01356871,  0.05650926,\n",
       "        0.00561938,  0.0037191 ,  0.01798356,  0.01952919,  0.06547432,\n",
       "        0.00827154, -0.01932704, -0.02344681, -0.00920292,  0.03154224,\n",
       "       -0.03649767,  0.08117408, -0.03917187, -0.00345648,  0.05138877,\n",
       "       -0.00199704,  0.05113884,  0.02644985,  0.07333578, -0.01576789,\n",
       "       -0.01111526,  0.00616771,  0.00132414,  0.01506105,  0.08244497,\n",
       "        0.03458769,  0.00336031, -0.01843923,  0.02891117,  0.02234494,\n",
       "        0.10053216, -0.01043958,  0.00050939,  0.01510428, -0.00804148,\n",
       "        0.06222738,  0.03545911,  0.0219524 ,  0.10040974,  0.00963782,\n",
       "        0.01274001,  0.01586713,  0.0144221 ,  0.04834748, -0.02233005],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
