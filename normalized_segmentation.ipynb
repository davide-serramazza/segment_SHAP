{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:14.883705Z",
     "start_time": "2024-10-23T12:00:14.664669Z"
    }
   },
   "source": "%reset -f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# imports"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:07:28.215143Z",
     "start_time": "2024-10-23T14:07:28.209904Z"
    }
   },
   "source": [
    "from captum.attr import ShapleyValueSampling\n",
    "from load_data import load_data\n",
    "from models.model_wrappers import *\n",
    "from models.train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "import sys\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "# device for torch\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# device for torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:07:35.447731Z",
     "start_time": "2024-10-23T14:07:35.441378Z"
    }
   },
   "source": [
    "\n",
    "# settings\n",
    "dataset_names = {'UWAVE'}    #{sys.argv[1]}\n",
    "predictor_names = {'resNet'}    #{sys.argv[2]} {\"randomForest\", 'miniRocket', 'resNet'}\n",
    "segmentation_names = [ \"equal\" ] #,\"clasp\",\"greedygaussian\", \"infogain\",\"nnsegment\"]  # {\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"} # {\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"} \n",
    "background_names =  [ \"sampling\", \"average\" , \"zero\"] # , \"sampling\",] #{\"average\", \"zero\", \"sampling\"}\n",
    "normalization_names = {\"default\", \"normalized\"}\n",
    "\n",
    "demo_mode = False\n",
    "# demo\n",
    "if demo_mode:\n",
    "    dataset_names = {'gunpoint'}\n",
    "    predictor_names = {\"randomForest\"}\n",
    "    segmentation_names = { \"equal\"} #,'clasp'}\n",
    "    background_names ={\"average\",\"sampling\"} #,'sampling'}\n",
    "    normalization_names = {\"default\", \"normalized\"}\n"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# instantiate dictionaries that gonna be used in the pipeline"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:07:36.900482Z",
     "start_time": "2024-10-23T14:07:36.893869Z"
    }
   },
   "source": [
    "# dictionary mapping predictors to torch vs other, step necessary for Captum \n",
    "predictors = {\n",
    "    'torch' : ['resNet'],\n",
    "    'scikit' : ['miniRocket','randomForest','QUANT']\n",
    "}\n",
    "segmentation_dict = {\"clasp\":get_claSP_segmentation, \"infogain\": get_InformationGain_segmentation, \"greedygaussian\": get_GreedyGaussian_segmentation, \"equal\": get_equal_segmentation, \"nnsegment\": get_NNSegment_segmentation}\n",
    "\n",
    "results = dict.fromkeys(('y_test_true', 'label_mapping', \"segments\", 'y_test_pred', \"attributions\"))\n",
    "for key in results.keys():\n",
    "    results[key] = dict.fromkeys(dataset_names)\n",
    "    \n",
    "normalization_names = normalization_names | {\"default\"}\n"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:09:40.358909Z",
     "start_time": "2024-10-23T14:09:39.632943Z"
    }
   },
   "source": [
    "from models.predictor_utils import load_predictor, predict_proba\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # init dataset\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "    # for debugging only\n",
    "    if demo_mode:\n",
    "        X_test = X_test[:2]\n",
    "        y_test = y_test[:2]\n",
    "\n",
    "    n_samples, n_chs, ts_length = X_test.shape\n",
    "\n",
    "    results['y_test_true'][dataset_name] = y_test\n",
    "    results['label_mapping'][dataset_name] = enc\n",
    "    results[\"attributions\"][dataset_name] = dict.fromkeys(segmentation_names)\n",
    "    results[\"segments\"][dataset_name] = dict.fromkeys(segmentation_names)\n",
    "    results[\"y_test_pred\"][dataset_name] = dict.fromkeys(predictor_names)\n",
    "\n",
    "    predictor_dict = dict()\n",
    "    # TODO not to save if in demo mode!\n",
    "    for predictor_name in predictor_names:\n",
    "        if demo_mode:\n",
    "            dataset_name=None\n",
    "\n",
    "        if predictor_name=='resNet':\n",
    "            # TODO rollback to normal!!!!!!!!!!!!!!\n",
    "            clf = load_predictor(path=\"trained_models\",predictor_name=\"resNet\",dataset_name=dataset_name,device=\"cuda\")\n",
    "            preds = predict_proba(clf,samples=X_test,device=\"cuda\")\n",
    "            #clf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "        elif predictor_name=='miniRocket':\n",
    "            clf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "        elif predictor_name==\"randomForest\":\n",
    "            clf, preds = train_randomForest(X_train, y_train, X_test, y_test, dataset_name)\n",
    "        elif predictor_name==\"QUANT\":\n",
    "            clf, preds = train_QUANT(X_train, y_train, X_test, y_test, dataset_name)\n",
    "        else:\n",
    "            raise ValueError(\"predictor not found\")\n",
    "\n",
    "        predictor_dict[predictor_name] = {\"clf\": clf, \"preds\": preds}\n"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[64], line 29\u001B[0m\n\u001B[1;32m     25\u001B[0m     dataset_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m predictor_name\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresNet\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# TODO rollback to normal!!!!!!!!!!!!!!\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     clf \u001B[38;5;241m=\u001B[39m load_predictor(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrained_models\u001B[39m\u001B[38;5;124m\"\u001B[39m,predictor_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresNet\u001B[39m\u001B[38;5;124m\"\u001B[39m,dataset_name\u001B[38;5;241m=\u001B[39mdataset_name,device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     30\u001B[0m     preds \u001B[38;5;241m=\u001B[39m predict_proba(clf,samples\u001B[38;5;241m=\u001B[39mX_test,device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m#clf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/PhD/bristolSHAP/models/predictor_utils.py:34\u001B[0m, in \u001B[0;36mload_predictor\u001B[0;34m(path, predictor_name, dataset_name, device)\u001B[0m\n\u001B[1;32m     32\u001B[0m \t\u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m \t\tdevice \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 34\u001B[0m \tpredictor \u001B[38;5;241m=\u001B[39m load_torch(model_path\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m, map_location\u001B[38;5;241m=\u001B[39mdevice)\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     35\u001B[0m \tpredictor \u001B[38;5;241m=\u001B[39m Sequential(predictor, Softmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:1026\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1024\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1025\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1026\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile,\n\u001B[1;32m   1027\u001B[0m                      map_location,\n\u001B[1;32m   1028\u001B[0m                      pickle_module,\n\u001B[1;32m   1029\u001B[0m                      overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[1;32m   1030\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1031\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1033\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1034\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:1438\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1436\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1437\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1438\u001B[0m result \u001B[38;5;241m=\u001B[39m unpickler\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m   1440\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1441\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[1;32m   1443\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:1408\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1407\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1408\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001B[1;32m   1410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:1382\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1377\u001B[0m         storage\u001B[38;5;241m.\u001B[39mbyteswap(dtype)\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[1;32m   1380\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[1;32m   1381\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[0;32m-> 1382\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39mrestore_location(storage, location),\n\u001B[1;32m   1383\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1384\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1387\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:1308\u001B[0m, in \u001B[0;36m_get_restore_location.<locals>.restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrestore_location\u001B[39m(storage, location):\n\u001B[0;32m-> 1308\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_restore_location(storage, map_location)\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:391\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 391\u001B[0m         result \u001B[38;5;241m=\u001B[39m fn(storage, location)\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    393\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/serialization.py:271\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    269\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mUntypedStorage(obj\u001B[38;5;241m.\u001B[39mnbytes(), device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(location))\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mcuda(device)\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/torch/_utils.py:118\u001B[0m, in \u001B[0;36m_cuda\u001B[0;34m(self, device, non_blocking, **kwargs)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m     untyped_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mUntypedStorage(\n\u001B[1;32m    116\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize(), device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    117\u001B[0m     )\n\u001B[0;32m--> 118\u001B[0m     untyped_storage\u001B[38;5;241m.\u001B[39mcopy_(\u001B[38;5;28mself\u001B[39m, non_blocking)\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m untyped_storage\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:03:18.413478Z",
     "start_time": "2024-10-23T09:03:18.410147Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T08:59:28.460016Z",
     "start_time": "2024-10-23T08:59:28.457879Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def initialize_result_dict(X_test,predictor_names,dataset_name,segmentation_name,results):\n",
    "\tinit_segments = np.empty((X_test.shape[0], X_test.shape[1]), dtype=object) if X_test.shape[1] > 1 else (\n",
    "\t\tnp.empty(X_test.shape[0], dtype=object))\n",
    "\tresults[\"segments\"][dataset_name][segmentation_name] = init_segments.copy()\n",
    "\tresults[\"attributions\"][dataset_name][segmentation_name] = dict.fromkeys(predictor_names)\n",
    "\tfor predictor_name in predictor_names:\n",
    "\t\tresults[\"attributions\"][dataset_name][segmentation_name][predictor_name] = dict.fromkeys(background_names)\n",
    "\n",
    "\n",
    "def get_sample_info(segmentation_method, X_test,y_test,results, id, mask_list, ts_list, y_list):\n",
    "\t# get current sample and label\n",
    "\tts, y = X_test[id], torch.tensor(y_test[id:id + 1])\n",
    "\t# get segment and its tensor representation\n",
    "\tcurrent_segments = segmentation_method(ts)[:X_test.shape[1]]\n",
    "\tresults['segments'][dataset_name][segmentation_name][i] = current_segments\n",
    "\tmask = get_feature_mask(current_segments, ts.shape[-1])\n",
    "\tmask_list.append(mask)\n",
    "\tts = torch.tensor(ts).repeat(1, 1, 1)  # TODO use something similar to np.expand_dim?\n",
    "\tts_list.append(ts)\n",
    "\ty_list.append(y)\n",
    "\treturn ts,y,mask\n",
    "\n",
    "\n",
    "from utils import sample_background\n",
    "def get_background( background_name, results, normalization_names, X_train, n_background=50):\n",
    "\n",
    "\tresults[\"attributions\"][dataset_name][segmentation_name][predictor_name][background_name] = dict.fromkeys(\n",
    "\t\tnormalization_names)\n",
    "\t# background data\n",
    "\tif background_name == \"zero\":\n",
    "\t\tbackground_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "\telif background_name == \"sampling\":\n",
    "\t\tbackground_dataset = sample_background(X_train, n_background)\n",
    "\telif background_name == \"average\":\n",
    "\t\tbackground_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "\n",
    "\treturn background_dataset\n",
    "\n",
    "\n",
    "def get_attribution(ts, mask, background_dataset,y, results ): #    global ts, mask, background_dataset, tmp, y\n",
    "    if len(background_dataset)==4:\n",
    "        # in this case background is 'SAMPLING'\n",
    "        # get rid of first dimension as it's always 1\n",
    "        ts = ts[0] ;  mask= mask[0] ; background_dataset= background_dataset[0] ; y=y[0]\n",
    "        \n",
    "    if predictor_name in predictors['scikit']:\n",
    "\t\t# if using random forest flat everything\n",
    "\t\t#if predictor_name == \"randomForest\":\n",
    "\t\t#\tts = ts.reshape(-1, n_chs * ts_length)\n",
    "\t\t#\tmask = mask.reshape(-1, n_chs * ts_length)\n",
    "\t\t#\tbackground_dataset = background_dataset.reshape(-1, n_chs * ts_length)\n",
    "\n",
    "        tmp = SHAP.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\n",
    "    elif predictor_name in predictors['torch']:\n",
    "\t\t# if use torch make sure everything is on selected device\n",
    "\t\tts = ts.to(device); y = y.to(device) ; mask = mask.to(device); background_dataset = background_dataset.to(device)\n",
    "\t\ttmp = SHAP.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset)\n",
    "\n",
    "\t# in case of random forest 'un-flatten' result\n",
    "    if predictor_name==\"randomForest\":\n",
    "\t\ttmp = tmp.reshape(-1,X_test.shape[1],X_test.shape[2])\n",
    "\n",
    "\t# lastly store current explanation in the data structure; if sampling store the mean\n",
    "    results['attributions'][dataset_name][segmentation_name][predictor_name][background_name][\"default\"][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "\t\tbackground_name==\"sampling\" else tmp[0].cpu().numpy()\n",
    "\n",
    "\n",
    "def get_normalized_results(normalization_names,results):\n",
    "\tif \"normalized\" in normalization_names:\n",
    "\t\tweights = np.array(list(map(\n",
    "\t\t\tlambda segmentation: list(map(\n",
    "\t\t\t\tlambda channel_segemnts: lengths_to_weights(change_points_to_lengths(channel_segemnts, X_train.shape[-1])),\n",
    "\t\t\t\tsegmentation)),\n",
    "\t\t\tresults[\"segments\"][dataset_name][segmentation_name])))\n",
    "\n",
    "\t\tresults['attributions'][dataset_name][segmentation_name][predictor_name][background_name][\"normalized\"] = \\\n",
    "\t\t\tresults['attributions'][dataset_name][segmentation_name][predictor_name][background_name][\"default\"] * weights\n",
    "\tif \"default\" not in normalization_names:\n",
    "\t\tdel results['attributions'][dataset_name][segmentation_name][predictor_name][background_name][\"default\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:28.981971Z",
     "start_time": "2024-10-23T12:00:28.978345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_result_dict(X_test,predictor_names,dataset_name,segmentation_name,results):\n",
    "    \n",
    "    init_segments = np.empty((X_test.shape[0], X_test.shape[1]), dtype=object) if X_test.shape[1] > 1 else ( np.empty(X_test.shape[0], dtype=object))\n",
    "    results[\"segments\"][dataset_name][segmentation_name] = init_segments.copy()\n",
    "    results[\"attributions\"][dataset_name][segmentation_name] = dict.fromkeys(predictor_names)\n",
    "    for predictor_name in predictor_names:\n",
    "        results[\"attributions\"][dataset_name][segmentation_name][predictor_name] = dict.fromkeys(background_names)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:29.126066Z",
     "start_time": "2024-10-23T12:00:29.123037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sample_info(segmentation_method,segmentation_name, idx, X_test,y_test,results, id, mask_list, ts_list, y_list):\n",
    "    \n",
    "    # get current sample and label\n",
    "    ts, y = X_test[id], torch.tensor(y_test[id:id + 1])\n",
    "    # get segment and its tensor representation\n",
    "    current_segments = segmentation_method(ts)[:X_test.shape[1]]\n",
    "    results['segments'][dataset_name][segmentation_name][idx] = current_segments\n",
    "    mask = get_feature_mask(current_segments, ts.shape[-1])\n",
    "    mask_list.append(mask)\n",
    "    ts = torch.tensor(ts).repeat(1, 1, 1)  # TODO use something similar to np.expand_dim?\n",
    "    ts_list.append(ts)\n",
    "    y_list.append(y)\n",
    "    return ts,y,mask\n"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:29.277218Z",
     "start_time": "2024-10-23T12:00:29.274415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import sample_background\n",
    "\n",
    "def get_background( background_name, segmentation_name, results, normalization_names, X_train, n_background=50):\n",
    "\n",
    "    results[\"attributions\"][dataset_name][segmentation_name][predictor_name][background_name] = dict.fromkeys(\n",
    "        normalization_names)\n",
    "    # background data\n",
    "    if background_name == \"zero\":\n",
    "        background_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "    elif background_name == \"sampling\":\n",
    "        background_dataset = sample_background(X_train, n_background)\n",
    "    elif background_name == \"average\":\n",
    "        background_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "\n",
    "    return background_dataset\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:29.418558Z",
     "start_time": "2024-10-23T12:00:29.414432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_attribution(explainer, ts, mask, background_dataset,y, sampling ): #    global ts, mask, background_dataset, tmp, y\n",
    "    \n",
    "    if sampling:\n",
    "        # get rid of first dimension as it's always 1\n",
    "        # TODO try to flatten multiple singles \"50 samples\" into a 3D dataset and get the performances of that\n",
    "        ts = ts[0] ;  mask= mask[0] ; y=y[0]\n",
    "\n",
    "    if predictor_name in predictors['scikit']:\n",
    "        # if using random forest flat everything\n",
    "        #if predictor_name == \"randomForest\":\n",
    "        #\tts = ts.reshape(-1, n_chs * ts_length)\n",
    "        #\tmask = mask.reshape(-1, n_chs * ts_length)\n",
    "        #\tbackground_dataset = background_dataset.reshape(-1, n_chs * ts_length)\n",
    "\n",
    "        tmp = explainer.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\n",
    "    elif predictor_name in predictors['torch']:\n",
    "        # if use torch make sure everything is on selected device\n",
    "        ts = ts.to(device); y = y.to(device) ; mask = mask.to(device); background_dataset = background_dataset.to(device)\n",
    "        tmp = explainer.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset)\n",
    "\n",
    "    # in case of random forest 'un-flatten' result\n",
    "    if predictor_name==\"randomForest\":\n",
    "        tmp = tmp.reshape(-1,X_test.shape[1],X_test.shape[2])\n",
    "\n",
    "    # lastly store current explanation in the data structure; if sampling store the mean\n",
    "    saliency_map = torch.mean(tmp, dim=0).cpu().numpy() if sampling else tmp.cpu().numpy()\n",
    "    return saliency_map\n"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:29.658604Z",
     "start_time": "2024-10-23T12:00:29.654463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def store_results(table, segmentation_name, normalization_names, current_results, start):\n",
    "    n_results = current_results.shape[0]\n",
    "    if 'default' in normalization_names:\n",
    "        table['default'][start: (start+n_results) ] = current_results\n",
    "\n",
    "    \n",
    "    # TODO to be improved!\n",
    "    if \"normalized\" in normalization_names:\n",
    "        weights = np.array(list(map(\n",
    "            lambda segmentation: list(map(\n",
    "                lambda channel_segemnts: lengths_to_weights(change_points_to_lengths(channel_segemnts, X_train.shape[-1])),\n",
    "                segmentation)),\n",
    "            results[\"segments\"][dataset_name][segmentation_name][start: (start+n_results) ]  )))\n",
    "        \n",
    "        table['normalized'][start: (start+n_results) ]  = current_results * weights\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:29.942760Z",
     "start_time": "2024-10-23T12:00:29.940625Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:00:30.427131Z",
     "start_time": "2024-10-23T12:00:30.425337Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DO WE WANT A STATIC BACKGROUND????????????????????????????????????????????????"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:21:03.131231Z",
     "start_time": "2024-10-23T12:00:30.706974Z"
    }
   },
   "source": [
    "\n",
    "starttime = timeit.default_timer()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dataset_name in dataset_names:\n",
    "        for predictor_name in predictor_names:\n",
    "            results['y_test_pred'][dataset_name][predictor_name] = predictor_dict[predictor_name][\"preds\"]\n",
    "        for segmentation_name in segmentation_names:\n",
    "            initialize_result_dict(X_test,predictor_names,dataset_name,segmentation_name,results)\n",
    "            segmentation_method = segmentation_dict[segmentation_name]\n",
    "            \n",
    "            ts_list = []\n",
    "            mask_list = []\n",
    "            y_list = []\n",
    "            \n",
    "            for i in range(n_samples) : \n",
    "                ts,y,mask = get_sample_info( segmentation_method,segmentation_name, i , X_test,y_test, results, i, mask_list, ts_list, y_list)\n",
    "            \n",
    "            for background_name in background_names:\n",
    "                background_dataset = get_background( background_name, segmentation_name, results, normalization_names, X_train)\n",
    "\n",
    "                for predictor_name in predictor_names:\n",
    "                    # get clf and initialize attributions\n",
    "                    clf = predictor_dict[predictor_name][\"clf\"]\n",
    "                    init_attributions = np.zeros(X_test.shape, dtype=np.float32)\n",
    "                    for normalization_name in normalization_names:\n",
    "                        results['attributions'][dataset_name][segmentation_name][predictor_name][background_name][normalization_name] = init_attributions.copy()\n",
    "\n",
    "                    \n",
    "                    SHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "                    \n",
    "                    # prepare for batch computation\n",
    "                    batch_size = 1 if background_name=='sampling' else 50 #HARD CODEEEEEEED!!!!!!!!!!!!!!!\n",
    "                    from models.SHAP_dataloader import SHAP_dataloader\n",
    "                    from torch.utils.data import DataLoader\n",
    "                    data_loader = DataLoader( SHAP_dataloader(ts_list,y_list,mask_list, background_dim=background_dataset.shape[0] ) ,  batch_size=batch_size )\n",
    "                    \n",
    "                    # actually computing\n",
    "                    current_idx = 0\n",
    "                    with tqdm(total=len(ts_list)) as pbar:\n",
    "                        for (ts,y,mask) in data_loader:\n",
    "                            #print ( segmentation_method, ts.shape,y.shape,mask.shape,background.shape)\n",
    "                            current_results = get_attribution( SHAP, ts,mask,background_dataset,y, \n",
    "                                    sampling= (background_name=='sampling') )\n",
    "                            \n",
    "                            #results['attributions'][dataset_name][segmentation_name][predictor_name][background_name]\n",
    "                            store_results(table=results['attributions'][dataset_name][segmentation_name][predictor_name][background_name], segmentation_name =segmentation_name, normalization_names=normalization_names,\n",
    "                                          current_results=current_results, start=current_idx)\n",
    "                            \n",
    "                            \n",
    "                            #def store_results(table, segmentation_name, normalization_names, current_results, start):\n",
    "\n",
    "                            pbar.update(batch_size) ; current_idx+=batch_size\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                    \n",
    "                    #with tqdm(total=len(ts_list)) as pbar:\n",
    "                    #    for i, (ts, mask, y) in enumerate(zip(ts_list, mask_list, y_list)):\n",
    "                    #        # for sampling strategy repeat the ts many times as the background dataset size\n",
    "                    #        ts = ts.repeat(background_dataset.shape[0],1,1) if background_name==\"sampling\" else ts\n",
    "                    #        get_attribution (ts, mask, background_dataset,y, results )\n",
    "                            # update tqdm\n",
    "                    #        pbar.update(1)\n",
    "                    #        if i==10:\n",
    "                    #            break\n",
    "                            \n",
    "                    pbar.close()\n",
    "                    # TODO understand how thi normalised results were computed \n",
    "                    #get_normalized_results(normalization_names,results)\n",
    "                    \n",
    "print(\"elapsed time\", ( timeit.default_timer() -starttime ) )\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428/428 [19:43<00:00,  2.77s/it]\n",
      "450it [00:24, 18.32it/s]                         \n",
      "450it [00:24, 18.73it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 1232.4164527829998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T12:21:19.597149Z",
     "start_time": "2024-10-23T12:21:19.593739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ttmp =  results['attributions'][dataset_name][segmentation_name][predictor_name]\n",
    "for k in ttmp.keys():\n",
    "    print( \"\\n\\n\", k)\n",
    "    for norm in [ 'default']:\n",
    "        ttttmp = np.sum(np.abs(ttmp[k][norm]) , axis= -1)\n",
    "        print( ttttmp , ttttmp.shape )\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " sampling\n",
      "[[11.582408  24.254623  35.691555 ]\n",
      " [ 7.3367586  9.266972   6.6268415]\n",
      " [25.880638  27.253008  18.168533 ]\n",
      " ...\n",
      " [28.691757   9.965157  17.066982 ]\n",
      " [12.745036  30.071623  19.087353 ]\n",
      " [31.189804   9.798238  13.231202 ]] (428, 3)\n",
      "\n",
      "\n",
      " average\n",
      "[[29.683067  21.247822  29.267376 ]\n",
      " [ 3.9951653  6.4947567  2.620192 ]\n",
      " [18.54258   32.54339   42.619137 ]\n",
      " ...\n",
      " [19.117561  35.358078  30.521587 ]\n",
      " [33.42269   21.398525  11.332826 ]\n",
      " [25.153896  28.398335  36.558273 ]] (428, 3)\n",
      "\n",
      "\n",
      " zero\n",
      "[[43.885323  21.24476   28.068007 ]\n",
      " [ 0.8967617  2.3241808  2.368327 ]\n",
      " [23.453777   6.1439085 38.005104 ]\n",
      " ...\n",
      " [13.480526  16.435982  46.407093 ]\n",
      " [29.20761   19.735928  14.694554 ]\n",
      " [11.833488  11.819376  45.91996  ]] (428, 3)\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T16:48:53.490948Z",
     "start_time": "2024-10-22T16:48:53.485040Z"
    }
   },
   "source": [
    "# dump result to disk\n",
    "if not demo_mode:\n",
    "    file_name = \"_\".join( (\"all_results\",dataset_name,predictor_name) )\n",
    "else:\n",
    "\tfile_name = \"_\".join( (\"all_results_DEMO_\",dataset_name,predictor_name) )\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T10:19:34.089808Z",
     "start_time": "2024-08-23T10:19:34.086307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gunpoint': {'QUANT': array([[0.985, 0.015],\n",
       "         [0.015, 0.985]])}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"y_test_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
