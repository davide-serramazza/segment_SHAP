{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:17:24.449528Z",
     "start_time": "2024-06-10T15:17:24.444502Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from captum.attr import ShapleyValueSampling\n",
    "from tqdm import trange\n",
    "\n",
    "from load_data import load_data\n",
    "from train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:17:24.902489Z",
     "start_time": "2024-06-10T15:17:24.898786Z"
    }
   },
   "outputs": [],
   "source": [
    "# to utils.py\n",
    "\n",
    "def change_points_to_lengths(change_points, array_length):\n",
    "    # change points is 1D iterable of idxs\n",
    "    # assumes that each change point is the start of a new segment, aka change_points = start points\n",
    "    start_points = np.array(change_points)\n",
    "    end_points = np.append(change_points[1:], [array_length])\n",
    "    print(start_points, end_points)\n",
    "    lengths = end_points - start_points\n",
    "    return lengths\n",
    "\n",
    "def lengths_to_weights(lengths):\n",
    "    # lengths is 1D iterable of positive ints\n",
    "    start_idx = 0\n",
    "    end_idx = 0\n",
    "    segment_weights = 1 / lengths\n",
    "    weights = np.ones(lengths.sum())\n",
    "    for segment_weight, length in zip(segment_weights, lengths):\n",
    "        end_idx += length\n",
    "        weights[start_idx: end_idx] = segment_weight\n",
    "        start_idx = end_idx\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:17:25.513811Z",
     "start_time": "2024-06-10T15:17:25.509764Z"
    }
   },
   "outputs": [],
   "source": [
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\"\n",
    "\n",
    "# dictionary mapping predictors to torch vs other, necessary for Captum \n",
    "predictors = {\n",
    "\t'torch' : ['resNet'],\n",
    "\t'scikit' : ['miniRocket','randomForest']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:17:28.138222Z",
     "start_time": "2024-06-10T15:17:26.892146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ResNet\n",
      "Epoch 1: train loss:  0.675, \t train accuracy  0.660 \n",
      "          test loss:  0.597,  \t test accuracy  0.787\n",
      "Epoch 11: train loss:  0.267, \t train accuracy  0.940 \n",
      "          test loss:  0.326,  \t test accuracy  0.927\n",
      "Epoch 21: train loss:  0.119, \t train accuracy  1.000 \n",
      "          test loss:  0.164,  \t test accuracy  1.000\n",
      "Epoch 31: train loss:  0.067, \t train accuracy  1.000 \n",
      "          test loss:  0.109,  \t test accuracy  1.000\n",
      "Epoch 41: train loss:  0.049, \t train accuracy  1.000 \n",
      "          test loss:  0.089,  \t test accuracy  1.000\n",
      "training early stopped! Final stats are:\n",
      "Epoch 45: train loss:  0.066, \t train accuracy  1.000 \n",
      "          test loss:  0.079,  \t test accuracy  1.000\n",
      "accuracy for resNet is  1.0\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset_name = 'gunpoint'\n",
    "predictor_name = 'resNet'\n",
    "\n",
    "# I've returned also a Label encoder from load_data to have a mapping between dataset label\n",
    "# which can be string while captum requires idx (integers)\n",
    "X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "\n",
    "# train model\n",
    "if predictor_name=='resNet':\n",
    "\tclf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "elif predictor_name=='miniRocket':\n",
    "\tclf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "\n",
    "# create a dictionary to be dumped containing attribution and metadata\n",
    "# initialize data structure meant to contain the segments\n",
    "segments =  np.empty( (X_test.shape[0] , X_test.shape[1]), dtype=object) if X_test.shape[1] > 1  else (\n",
    "\tnp.empty( X_test.shape[0] , dtype=object))\n",
    "\n",
    "results = {\n",
    "\t'attributions' : {},\n",
    "\t'segments' : segments,\n",
    "\t'y_test_true' : y_test,\n",
    "\t'y_test_pred' : preds,\n",
    "\t'label_mapping' : enc,\n",
    "}"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:24:37.007328Z",
     "start_time": "2024-06-11T13:24:37.004283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_background = 50\n",
    "background_types = [\"average\", \"zero\",\"sampling\"] # zero, constant, average, multisample\n",
    "for type in background_types:\n",
    "\tresults['attributions'][type] = np.zeros( X_test.shape ,dtype=np.float32 )"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:25:05.319658Z",
     "start_time": "2024-06-11T13:25:03.584911Z"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "\tSHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "\n",
    "\tfor i in trange ( X_test.shape[0] ) : #\n",
    "\n",
    "\t\t# get current sample and label\n",
    "\t\tts, y = X_test[i] , torch.tensor( y_test[i:i+1] )\n",
    "\n",
    "\t\t# get segment and its tensor representation\n",
    "\t\tcurrent_segments = get_claSP_segmentation(ts)[:X_test.shape[1]]\n",
    "\t\tresults['segments'][i] = current_segments\n",
    "\t\tmask = get_feature_mask(current_segments,ts.shape[-1])\n",
    "\n",
    "\t\tts = torch.tensor(ts).repeat(1,1,1)\n",
    "\n",
    "\t\tfor background_type in background_types:\n",
    "\n",
    "\n",
    "\t\t\t# background data\n",
    "\t\t\tif background_type==\"zero\":\n",
    "\t\t\t\tbackground_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "\t\t\telif background_type==\"sampling\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background)\n",
    "\t\t\telif background_type==\"average\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "\n",
    "\t\t\tts = ts.repeat(background_dataset.shape[0],1,1) if background_type==\"sampling\" else ts\n",
    "\n",
    "\t\t\t# data structure with room for each sample in the background dataset\n",
    "\t\t\tif predictor_name in predictors['scikit']:\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\t\t\telif predictor_name in predictors['torch']:\n",
    "\t\t\t\tts = ts.to(device); y = y.to(device)\n",
    "\t\t\t\tmask = mask.to(device) ; background_dataset =  background_dataset.to(device)\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset)\n",
    "\t\t\t########  only for random forest as every instance should be a 1D tensor    ########\n",
    "\t\t\t#current_attr[j:j+actual_size] = tmp.reshape(actual_size,X_test.shape[1],X_test.shape[2])\n",
    "\t\t\t###############################################################################\n",
    "\n",
    "\t\t\t# compute as final explanation mean of each explanation using a different baseline\n",
    "\t\t\tresults['attributions'][background_type][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "\t\t\t\tbackground_type==\"sampling\" else tmp[0].cpu().numpy()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:01<03:52,  1.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 35\u001B[0m\n\u001B[1;32m     33\u001B[0m \tts \u001B[38;5;241m=\u001B[39m ts\u001B[38;5;241m.\u001B[39mto(device); y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     34\u001B[0m \tmask \u001B[38;5;241m=\u001B[39m mask\u001B[38;5;241m.\u001B[39mto(device) ; background_dataset \u001B[38;5;241m=\u001B[39m  background_dataset\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 35\u001B[0m \ttmp \u001B[38;5;241m=\u001B[39m \u001B[43mSHAP\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattribute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43mts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaselines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackground_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m########  only for random forest as every instance should be a 1D tensor    ########\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m#current_attr[j:j+actual_size] = tmp.reshape(actual_size,X_test.shape[1],X_test.shape[2])\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m###############################################################################\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# compute as final explanation mean of each explanation using a different baseline\u001B[39;00m\n\u001B[1;32m     41\u001B[0m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattributions\u001B[39m\u001B[38;5;124m'\u001B[39m][background_type][i] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(tmp, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;28;01mif\u001B[39;00m \\\n\u001B[1;32m     42\u001B[0m \tbackground_type\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampling\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m tmp[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/log/__init__.py:42\u001B[0m, in \u001B[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:384\u001B[0m, in \u001B[0;36mShapleyValueSampling.attribute\u001B[0;34m(self, inputs, baselines, target, additional_forward_args, feature_mask, n_samples, perturbations_per_eval, show_progress)\u001B[0m\n\u001B[1;32m    377\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature mask is missing some integers between 0 and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    379\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_features, for optimal performance, make sure each\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m consecutive integer corresponds to a feature.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    381\u001B[0m     )\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# modified_eval dimensions: 1D tensor with length\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;66;03m# equal to #num_examples * #features in batch\u001B[39;00m\n\u001B[0;32m--> 384\u001B[0m modified_eval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strict_run_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_target\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_add_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m show_progress:\n\u001B[1;32m    391\u001B[0m     attr_progress\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:537\u001B[0m, in \u001B[0;36mShapleyValueSampling._strict_run_forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_strict_run_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    532\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;124;03m    A temp wrapper for global _run_forward util to force forward output\u001B[39;00m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;124;03m    type assertion & conversion.\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;124;03m    Remove after the strict logic is supported by all attr classes\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 537\u001B[0m     forward_output \u001B[38;5;241m=\u001B[39m \u001B[43m_run_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(forward_output, Tensor):\n\u001B[1;32m    539\u001B[0m         \u001B[38;5;66;03m# format scalar to shape (1) so we can always assume non-empty output_shape\u001B[39;00m\n\u001B[1;32m    540\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m forward_output\u001B[38;5;241m.\u001B[39mshape:\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/_utils/common.py:536\u001B[0m, in \u001B[0;36m_run_forward\u001B[0;34m(forward_func, inputs, target, additional_forward_args)\u001B[0m\n\u001B[1;32m    529\u001B[0m additional_forward_args \u001B[38;5;241m=\u001B[39m _format_additional_forward_args(additional_forward_args)\n\u001B[1;32m    531\u001B[0m output \u001B[38;5;241m=\u001B[39m forward_func(\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39madditional_forward_args)\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m additional_forward_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    534\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m inputs\n\u001B[1;32m    535\u001B[0m )\n\u001B[0;32m--> 536\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_select_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/_utils/common.py:586\u001B[0m, in \u001B[0;36m_select_targets\u001B[0;34m(output, target)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _verify_select_column(output, target)\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(target) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mint\u001B[39m):\n\u001B[1;32m    587\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _verify_select_column(output, cast(\u001B[38;5;28mint\u001B[39m, target\u001B[38;5;241m.\u001B[39mitem()))\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(target) \u001B[38;5;241m==\u001B[39m num_examples:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:25:20.130035Z",
     "start_time": "2024-06-11T13:25:20.124608Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # normalized weights\n",
    "weights = np.array(list(map(lambda x: list(map(lambda y: lengths_to_weights(change_points_to_lengths(y, X_train.shape[-1])), x)), results[\"segments\"])))\n",
    "results[\"attributions\"][background_type] *= weights"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:20:41.507345Z",
     "start_time": "2024-06-10T15:20:41.496612Z"
    }
   },
   "outputs": [],
   "source": [
    "# dump result to disk\n",
    "file_name = \"_\".join ( (dataset_name, predictor_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:42.722545Z",
     "start_time": "2024-06-10T14:23:42.718744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70120507e-01,  1.52841201e-02,  9.28617418e-02,  1.13407120e-01,\n",
       "        1.83220327e-01,  2.10560542e-02,  1.27464145e-01,  1.06733963e-01,\n",
       "        1.75181329e-02,  1.57249138e-01,  1.40664607e-01,  1.49215162e-01,\n",
       "        1.59901679e-02,  1.27517417e-01,  1.47278994e-01,  1.60658777e-01,\n",
       "        2.17270672e-01,  5.09824380e-02,  3.32470946e-02,  3.66214737e-02,\n",
       "        1.30641073e-01,  1.23184487e-01,  1.96215227e-01,  1.38463348e-01,\n",
       "        8.75410587e-02,  9.70023274e-02,  1.71967596e-01,  1.50519937e-01,\n",
       "        5.04426882e-02,  1.61408171e-01,  2.16436416e-01,  1.41229391e-01,\n",
       "        1.41947210e-01,  1.62317842e-01,  1.64650887e-01,  1.64535791e-01,\n",
       "        1.46388069e-01,  1.16750002e-01,  1.22873716e-01,  4.31026220e-02,\n",
       "        1.57310590e-01,  1.00012690e-01,  1.55799270e-01,  1.55326679e-01,\n",
       "        8.71996731e-02,  1.57125652e-01,  1.36757612e-01,  3.19495164e-02,\n",
       "        1.55807734e-01,  3.47837806e-02,  9.90368426e-05,  1.06972188e-01,\n",
       "        1.50174171e-01,  1.25235200e-01,  2.20670074e-01,  1.48426294e-01,\n",
       "        5.72129600e-02,  5.23135811e-03,  1.69855252e-01, -9.55441408e-03,\n",
       "        1.81595162e-01,  8.55566040e-02,  1.83773547e-01,  1.74469322e-01,\n",
       "        3.58385742e-02,  1.50771007e-01,  1.02175027e-01,  1.56581402e-03,\n",
       "        7.39983469e-03, -7.07995798e-03,  2.82760896e-02,  2.25948971e-02,\n",
       "        3.39109339e-02,  1.27417088e-01,  9.65246856e-02,  3.17281187e-02,\n",
       "        5.00109047e-03,  1.26921579e-01,  1.34369999e-01,  1.73745632e-01,\n",
       "        1.57104641e-01,  1.37270853e-01,  7.70949945e-02, -4.15297691e-04,\n",
       "        2.89354324e-02,  4.62383078e-03,  1.20482042e-01,  7.14676976e-02,\n",
       "        1.84177309e-01,  1.62069023e-01,  1.86456561e-01,  8.48496482e-02,\n",
       "        2.18016014e-01,  1.39586866e-01,  1.34663373e-01,  1.53521806e-01,\n",
       "        2.53173076e-02,  8.60062540e-02,  1.18714899e-01,  1.63239688e-01,\n",
       "        7.53705502e-02,  1.18462563e-01,  1.14391193e-01,  2.68483628e-02,\n",
       "        2.29834616e-02,  1.15697414e-01,  2.02667177e-01,  6.56441450e-02,\n",
       "        1.53643370e-01,  4.30381391e-03,  5.79964779e-02,  1.98596139e-02,\n",
       "        1.90514505e-01,  9.38736200e-02,  1.25028551e-01,  1.28209993e-01,\n",
       "        1.33996025e-01,  1.38196483e-01,  2.03438237e-01,  1.31943494e-01,\n",
       "        1.49502069e-01,  1.43413126e-01,  1.34794991e-02,  1.24804698e-01,\n",
       "        1.04686841e-01,  7.56240487e-02,  1.34499803e-01,  1.21700674e-01,\n",
       "        6.39081597e-02,  9.29444805e-02,  9.19372439e-02,  2.13646851e-02,\n",
       "        1.33988142e-01,  1.86901391e-01,  1.58457816e-01,  7.32089505e-02,\n",
       "        1.22220784e-01, -1.01578850e-02,  1.59590364e-01,  1.82752252e-01,\n",
       "        1.20933130e-01,  1.36274219e-01,  1.23209335e-01,  5.82058020e-02,\n",
       "        1.32585362e-01,  1.86867490e-02,  1.39303863e-01,  4.07059491e-02,\n",
       "        1.05080873e-01,  9.12766233e-02], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['attributions'][background_type].sum(axis=(1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
