{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:30.023546Z",
     "start_time": "2024-06-10T14:18:28.160520Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from captum.attr import ShapleyValueSampling\n",
    "from tqdm import trange\n",
    "\n",
    "from load_data import load_data\n",
    "from train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:30.650643Z",
     "start_time": "2024-06-10T14:18:30.647152Z"
    }
   },
   "source": [
    "# to utils.py\n",
    "\n",
    "def change_points_to_lengths(change_points, max_length):\n",
    "    # change points is 1D iterable of idxs\n",
    "    change_points = list(change_points)\n",
    "    start_points = [0] + change_points\n",
    "    end_points = change_points + [max_length]\n",
    "    lengths = np.array(end_points) - np.array(start_points)\n",
    "    return lengths\n",
    "\n",
    "def lengths_to_weights(lengths):\n",
    "    # lengths is 1D iterable of positive ints\n",
    "    start_idx = 0\n",
    "    end_idx = 0\n",
    "    segment_weights = 1 / lengths\n",
    "    weights = np.ones(lengths.sum())\n",
    "    for segment_weight, length in zip(segment_weights, lengths):\n",
    "        end_idx += length\n",
    "        weights[start_idx: end_idx] = segment_weight\n",
    "        start_idx = end_idx\n",
    "    return weights\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:34.909837Z",
     "start_time": "2024-06-10T14:18:34.667322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\"\n",
    "\n",
    "# dictionary mapping predictors to torch vs other, necessary for Captum \n",
    "predictors = {\n",
    "\t'torch' : ['resNet'],\n",
    "\t'scikit' : ['randomForest']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:37.807026Z",
     "start_time": "2024-06-10T14:18:35.660480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data\n",
    "dataset_name = 'gunpoint'\n",
    "predictor_name = 'resNet'\n",
    "\n",
    "# I've returned also a Label encoder from load_data to have a mapping between dataset label\n",
    "# which can be string while captum requires idx (integers)\n",
    "X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "\n",
    "# train model\n",
    "#clf, preds = train_randomForest(X_train,y_train,X_test,y_test, dataset_name)\n",
    "if predictor_name=='resNet':\n",
    "\tclf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "elif predictor_name=='miniRocket':\n",
    "\tclf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "\n",
    "# create a dictionary to be dumped containing attribution and metadata\n",
    "# initialize data structure meant to contain the segments\n",
    "segments =  np.empty( (X_test.shape[0] , X_test.shape[1]), dtype=object) if X_test.shape[1] > 1  else (\n",
    "\tnp.empty( X_test.shape[0] , dtype=object))\n",
    "\n",
    "results = {\n",
    "\t'attributions' : {},\n",
    "\t'segments' : segments,\n",
    "\t'y_test_true' : y_test,\n",
    "\t'y_test_pred' : preds,\n",
    "\t'label_mapping' : enc,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ResNet\n",
      "Epoch 1: train loss:  0.630, \t train accuracy  0.740 \n",
      "          test loss:  0.547,  \t test accuracy  0.820\n",
      "Epoch 11: train loss:  0.216, \t train accuracy  0.980 \n",
      "          test loss:  0.260,  \t test accuracy  0.973\n",
      "Epoch 21: train loss:  0.107, \t train accuracy  1.000 \n",
      "          test loss:  0.132,  \t test accuracy  1.000\n",
      "Epoch 31: train loss:  0.058, \t train accuracy  1.000 \n",
      "          test loss:  0.095,  \t test accuracy  1.000\n",
      "Epoch 41: train loss:  0.046, \t train accuracy  1.000 \n",
      "          test loss:  0.084,  \t test accuracy  1.000\n",
      "training early stopped! Final stats are:\n",
      "Epoch 50: train loss:  0.045, \t train accuracy  1.000 \n",
      "          test loss:  0.063,  \t test accuracy  1.000\n",
      "accuracy for resNet is  1.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:33.079499Z",
     "start_time": "2024-06-10T14:21:00.547665Z"
    }
   },
   "source": [
    "# explain\n",
    "n_background = 50\n",
    "background_types = [\"sampling\",\"average\",\"zero\",] # zero, constant, average, multisample\n",
    "\n",
    "# TODO for each baseline so that I don't retrain a model each time \n",
    "\n",
    "with torch.no_grad():\n",
    "    SHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "    \n",
    "    for background_type in background_types:\n",
    "    \n",
    "        results['attributions'][background_type] = np.empty( X_test.shape ,dtype=np.float32 )\n",
    "    \n",
    "        # background data\n",
    "        if background_type==\"zero\":\n",
    "            background_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "        elif background_type==\"sampling\":\n",
    "            background_dataset = sample_background(X_train, n_background)\n",
    "        elif background_type==\"average\":\n",
    "            background_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "    \n",
    "        for i in trange ( X_test.shape[0] ) : # \n",
    "    \n",
    "            # get current sample and label\n",
    "            ts, y = X_test[i] , torch.tensor( y_test[i:i+1] )\n",
    "    \n",
    "            # get segment and its tensor representation\n",
    "            current_segments = get_claSP_segmentation(ts)[:X_test.shape[1]]\n",
    "            results['segments'][i] = current_segments\n",
    "            mask = get_feature_mask(current_segments,ts.shape[-1])\n",
    "            ts = torch.tensor( [ts]* background_dataset.shape[0]) if background_type==\"sampling\" else torch.tensor( [ts] )\n",
    "    \n",
    "            # data structure with room for each sample in the background dataset\n",
    "            if predictor_name in predictors['scikit']:\n",
    "                tmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "            elif predictor_name in predictors['torch']:\n",
    "                ts = ts.to(device); y = y.to(device)\n",
    "                mask = mask.to(device) ; background_dataset =  background_dataset.to(device)\n",
    "    \n",
    "                tmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset)\n",
    "    \n",
    "            # compute as final explanation mean of each explanation using a different baseline\n",
    "            results['attributions'][background_type][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "                background_type==\"sampling\" else tmp.cpu().numpy()\n",
    "        \n",
    "        # normalized weights\n",
    "    weights = np.array(list(map(lambda x: list(map(lambda y: lengths_to_weights(change_points_to_lengths(y, X_train.shape[-1])), x)), results[\"segments\"])))\n",
    "    results[\"attributions\"][background_type] *= weights"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:25<00:00,  1.75it/s]\n",
      "100%|██████████| 150/150 [00:34<00:00,  4.38it/s]\n",
      "100%|██████████| 150/150 [00:32<00:00,  4.61it/s]\n",
      "/tmp/ipykernel_12671/3575056413.py:15: RuntimeWarning: divide by zero encountered in divide\n",
      "  segment_weights = 1 / lengths\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:38.321728Z",
     "start_time": "2024-06-10T14:23:38.317831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dump result to disk\n",
    "file_name = \"_\".join ( (dataset_name, predictor_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:42.722545Z",
     "start_time": "2024-06-10T14:23:42.718744Z"
    }
   },
   "source": "results['attributions'][background_type].sum(axis=(1,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70120507e-01,  1.52841201e-02,  9.28617418e-02,  1.13407120e-01,\n",
       "        1.83220327e-01,  2.10560542e-02,  1.27464145e-01,  1.06733963e-01,\n",
       "        1.75181329e-02,  1.57249138e-01,  1.40664607e-01,  1.49215162e-01,\n",
       "        1.59901679e-02,  1.27517417e-01,  1.47278994e-01,  1.60658777e-01,\n",
       "        2.17270672e-01,  5.09824380e-02,  3.32470946e-02,  3.66214737e-02,\n",
       "        1.30641073e-01,  1.23184487e-01,  1.96215227e-01,  1.38463348e-01,\n",
       "        8.75410587e-02,  9.70023274e-02,  1.71967596e-01,  1.50519937e-01,\n",
       "        5.04426882e-02,  1.61408171e-01,  2.16436416e-01,  1.41229391e-01,\n",
       "        1.41947210e-01,  1.62317842e-01,  1.64650887e-01,  1.64535791e-01,\n",
       "        1.46388069e-01,  1.16750002e-01,  1.22873716e-01,  4.31026220e-02,\n",
       "        1.57310590e-01,  1.00012690e-01,  1.55799270e-01,  1.55326679e-01,\n",
       "        8.71996731e-02,  1.57125652e-01,  1.36757612e-01,  3.19495164e-02,\n",
       "        1.55807734e-01,  3.47837806e-02,  9.90368426e-05,  1.06972188e-01,\n",
       "        1.50174171e-01,  1.25235200e-01,  2.20670074e-01,  1.48426294e-01,\n",
       "        5.72129600e-02,  5.23135811e-03,  1.69855252e-01, -9.55441408e-03,\n",
       "        1.81595162e-01,  8.55566040e-02,  1.83773547e-01,  1.74469322e-01,\n",
       "        3.58385742e-02,  1.50771007e-01,  1.02175027e-01,  1.56581402e-03,\n",
       "        7.39983469e-03, -7.07995798e-03,  2.82760896e-02,  2.25948971e-02,\n",
       "        3.39109339e-02,  1.27417088e-01,  9.65246856e-02,  3.17281187e-02,\n",
       "        5.00109047e-03,  1.26921579e-01,  1.34369999e-01,  1.73745632e-01,\n",
       "        1.57104641e-01,  1.37270853e-01,  7.70949945e-02, -4.15297691e-04,\n",
       "        2.89354324e-02,  4.62383078e-03,  1.20482042e-01,  7.14676976e-02,\n",
       "        1.84177309e-01,  1.62069023e-01,  1.86456561e-01,  8.48496482e-02,\n",
       "        2.18016014e-01,  1.39586866e-01,  1.34663373e-01,  1.53521806e-01,\n",
       "        2.53173076e-02,  8.60062540e-02,  1.18714899e-01,  1.63239688e-01,\n",
       "        7.53705502e-02,  1.18462563e-01,  1.14391193e-01,  2.68483628e-02,\n",
       "        2.29834616e-02,  1.15697414e-01,  2.02667177e-01,  6.56441450e-02,\n",
       "        1.53643370e-01,  4.30381391e-03,  5.79964779e-02,  1.98596139e-02,\n",
       "        1.90514505e-01,  9.38736200e-02,  1.25028551e-01,  1.28209993e-01,\n",
       "        1.33996025e-01,  1.38196483e-01,  2.03438237e-01,  1.31943494e-01,\n",
       "        1.49502069e-01,  1.43413126e-01,  1.34794991e-02,  1.24804698e-01,\n",
       "        1.04686841e-01,  7.56240487e-02,  1.34499803e-01,  1.21700674e-01,\n",
       "        6.39081597e-02,  9.29444805e-02,  9.19372439e-02,  2.13646851e-02,\n",
       "        1.33988142e-01,  1.86901391e-01,  1.58457816e-01,  7.32089505e-02,\n",
       "        1.22220784e-01, -1.01578850e-02,  1.59590364e-01,  1.82752252e-01,\n",
       "        1.20933130e-01,  1.36274219e-01,  1.23209335e-01,  5.82058020e-02,\n",
       "        1.32585362e-01,  1.86867490e-02,  1.39303863e-01,  4.07059491e-02,\n",
       "        1.05080873e-01,  9.12766233e-02], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:23:11.096492Z",
     "start_time": "2024-06-10T12:23:11.096307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "file_name = \"_\".join ( (dataset_name, predictor_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
