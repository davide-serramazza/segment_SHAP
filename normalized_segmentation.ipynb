{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:30.023546Z",
     "start_time": "2024-06-10T14:18:28.160520Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from captum.attr import ShapleyValueSampling\n",
    "from tqdm import trange\n",
    "\n",
    "from load_data import load_data\n",
    "from train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:30.650643Z",
     "start_time": "2024-06-10T14:18:30.647152Z"
    }
   },
   "source": [
    "# to utils.py\n",
    "\n",
    "def change_points_to_lengths(change_points, max_length):\n",
    "    # change points is 1D iterable of idxs\n",
    "    change_points = list(change_points)\n",
    "    start_points = [0] + change_points\n",
    "    end_points = change_points + [max_length]\n",
    "    lengths = np.array(end_points) - np.array(start_points)\n",
    "    return lengths\n",
    "\n",
    "def lengths_to_weights(lengths):\n",
    "    # lengths is 1D iterable of positive ints\n",
    "    start_idx = 0\n",
    "    end_idx = 0\n",
    "    segment_weights = 1 / lengths\n",
    "    weights = np.ones(lengths.sum())\n",
    "    for segment_weight, length in zip(segment_weights, lengths):\n",
    "        end_idx += length\n",
    "        weights[start_idx: end_idx] = segment_weight\n",
    "        start_idx = end_idx\n",
    "    return weights\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:12:49.218831Z",
     "start_time": "2024-06-10T15:12:49.210206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\"\n",
    "\n",
    "# dictionary mapping predictors to torch vs other, necessary for Captum \n",
    "predictors = {\n",
    "\t'torch' : ['resNet'],\n",
    "\t'scikit' : ['randomForest']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:12:53.672556Z",
     "start_time": "2024-06-10T15:12:51.462023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data\n",
    "dataset_name = 'gunpoint'\n",
    "predictor_name = 'resNet'\n",
    "\n",
    "# I've returned also a Label encoder from load_data to have a mapping between dataset label\n",
    "# which can be string while captum requires idx (integers)\n",
    "X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "\n",
    "# train model\n",
    "if predictor_name=='resNet':\n",
    "\tclf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "elif predictor_name=='miniRocket':\n",
    "\tclf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "\n",
    "# create a dictionary to be dumped containing attribution and metadata\n",
    "# initialize data structure meant to contain the segments\n",
    "segments =  np.empty( (X_test.shape[0] , X_test.shape[1]), dtype=object) if X_test.shape[1] > 1  else (\n",
    "\tnp.empty( X_test.shape[0] , dtype=object))\n",
    "\n",
    "results = {\n",
    "\t'attributions' : {},\n",
    "\t'segments' : segments,\n",
    "\t'y_test_true' : y_test,\n",
    "\t'y_test_pred' : preds,\n",
    "\t'label_mapping' : enc,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ResNet\n",
      "Epoch 1: train loss:  0.753, \t train accuracy  0.480 \n",
      "          test loss:  0.629,  \t test accuracy  0.620\n",
      "Epoch 11: train loss:  0.332, \t train accuracy  0.900 \n",
      "          test loss:  0.298,  \t test accuracy  0.933\n",
      "Epoch 21: train loss:  0.128, \t train accuracy  1.000 \n",
      "          test loss:  0.171,  \t test accuracy  0.993\n",
      "Epoch 31: train loss:  0.079, \t train accuracy  1.000 \n",
      "          test loss:  0.120,  \t test accuracy  0.993\n",
      "Epoch 41: train loss:  0.057, \t train accuracy  1.000 \n",
      "          test loss:  0.095,  \t test accuracy  1.000\n",
      "Epoch 51: train loss:  0.044, \t train accuracy  1.000 \n",
      "          test loss:  0.079,  \t test accuracy  1.000\n",
      "training early stopped! Final stats are:\n",
      "Epoch 55: train loss:  0.044, \t train accuracy  1.000 \n",
      "          test loss:  0.074,  \t test accuracy  1.000\n",
      "accuracy for resNet is  1.0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:12:56.507444Z",
     "start_time": "2024-06-10T15:12:53.674284Z"
    }
   },
   "source": [
    "# explain\n",
    "n_background = 50\n",
    "background_types = [\"sampling\",\"average\",\"zero\",] # zero, constant, average, multisample\n",
    "\n",
    "with torch.no_grad():\n",
    "    SHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "    \n",
    "    # I've added a for loop so that you're explaining the same classifier every time\n",
    "    for background_type in background_types:\n",
    "    \n",
    "        results['attributions'][background_type] = np.empty( X_test.shape ,dtype=np.float32 )\n",
    "    \n",
    "        # background data\n",
    "        if background_type==\"zero\":\n",
    "            background_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "        elif background_type==\"sampling\":\n",
    "            background_dataset = sample_background(X_train, n_background)\n",
    "        elif background_type==\"average\":\n",
    "            background_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "    \n",
    "        for i in trange ( X_test.shape[0] ) : # \n",
    "    \n",
    "            # get current sample and label\n",
    "            ts, y = X_test[i] , torch.tensor( y_test[i:i+1] )\n",
    "    \n",
    "            # get segment, its tensor representation and convert TSs to torch tensors\n",
    "            current_segments = get_claSP_segmentation(ts)[:X_test.shape[1]]\n",
    "            results['segments'][i] = current_segments\n",
    "            mask = get_feature_mask(current_segments,ts.shape[-1])\n",
    "            ts = torch.tensor( [ts]* background_dataset.shape[0]) if background_type==\"sampling\" else torch.tensor( [ts] )\n",
    "    \n",
    "            if predictor_name in predictors['scikit']:\n",
    "                tmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "            elif predictor_name in predictors['torch']:\n",
    "                clf.to(device); ts = ts.to(device); y = y.to(device)\n",
    "                mask = mask.to(device) ; background_dataset =  background_dataset.to(device)\n",
    "                tmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset)\n",
    "    \n",
    "            # compute as final explanation mean of each explanation using a different baseline\n",
    "            results['attributions'][background_type][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "                background_type==\"sampling\" else tmp.cpu().numpy()\n",
    "        \n",
    "        # normalized weights\n",
    "    weights = np.array(list(map(lambda x: list(map(lambda y: lengths_to_weights(change_points_to_lengths(y, X_train.shape[-1])), x)), results[\"segments\"])))\n",
    "    results[\"attributions\"][background_type] *= weights"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 3/150 [00:02<02:15,  1.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m     clf\u001B[38;5;241m.\u001B[39mto(device); ts \u001B[38;5;241m=\u001B[39m ts\u001B[38;5;241m.\u001B[39mto(device); y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     36\u001B[0m     mask \u001B[38;5;241m=\u001B[39m mask\u001B[38;5;241m.\u001B[39mto(device) ; background_dataset \u001B[38;5;241m=\u001B[39m  background_dataset\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 37\u001B[0m     tmp \u001B[38;5;241m=\u001B[39m \u001B[43mSHAP\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattribute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43mts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaselines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackground_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# compute as final explanation mean of each explanation using a different baseline\u001B[39;00m\n\u001B[1;32m     40\u001B[0m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattributions\u001B[39m\u001B[38;5;124m'\u001B[39m][background_type][i] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(tmp, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;28;01mif\u001B[39;00m \\\n\u001B[1;32m     41\u001B[0m     background_type\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampling\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m tmp\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/log/__init__.py:42\u001B[0m, in \u001B[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:384\u001B[0m, in \u001B[0;36mShapleyValueSampling.attribute\u001B[0;34m(self, inputs, baselines, target, additional_forward_args, feature_mask, n_samples, perturbations_per_eval, show_progress)\u001B[0m\n\u001B[1;32m    377\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature mask is missing some integers between 0 and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    379\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_features, for optimal performance, make sure each\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m consecutive integer corresponds to a feature.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    381\u001B[0m     )\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# modified_eval dimensions: 1D tensor with length\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;66;03m# equal to #num_examples * #features in batch\u001B[39;00m\n\u001B[0;32m--> 384\u001B[0m modified_eval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strict_run_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_target\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_add_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m show_progress:\n\u001B[1;32m    391\u001B[0m     attr_progress\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:537\u001B[0m, in \u001B[0;36mShapleyValueSampling._strict_run_forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_strict_run_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    532\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;124;03m    A temp wrapper for global _run_forward util to force forward output\u001B[39;00m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;124;03m    type assertion & conversion.\u001B[39;00m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;124;03m    Remove after the strict logic is supported by all attr classes\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 537\u001B[0m     forward_output \u001B[38;5;241m=\u001B[39m \u001B[43m_run_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(forward_output, Tensor):\n\u001B[1;32m    539\u001B[0m         \u001B[38;5;66;03m# format scalar to shape (1) so we can always assume non-empty output_shape\u001B[39;00m\n\u001B[1;32m    540\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m forward_output\u001B[38;5;241m.\u001B[39mshape:\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/_utils/common.py:536\u001B[0m, in \u001B[0;36m_run_forward\u001B[0;34m(forward_func, inputs, target, additional_forward_args)\u001B[0m\n\u001B[1;32m    529\u001B[0m additional_forward_args \u001B[38;5;241m=\u001B[39m _format_additional_forward_args(additional_forward_args)\n\u001B[1;32m    531\u001B[0m output \u001B[38;5;241m=\u001B[39m forward_func(\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39madditional_forward_args)\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m additional_forward_args \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    534\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m inputs\n\u001B[1;32m    535\u001B[0m )\n\u001B[0;32m--> 536\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_select_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/_utils/common.py:586\u001B[0m, in \u001B[0;36m_select_targets\u001B[0;34m(output, target)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _verify_select_column(output, target)\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(target, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(target) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mint\u001B[39m):\n\u001B[1;32m    587\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _verify_select_column(output, cast(\u001B[38;5;28mint\u001B[39m, target\u001B[38;5;241m.\u001B[39mitem()))\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(target) \u001B[38;5;241m==\u001B[39m num_examples:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:38.321728Z",
     "start_time": "2024-06-10T14:23:38.317831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dump result to disk\n",
    "file_name = \"_\".join ( (dataset_name, predictor_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:23:42.722545Z",
     "start_time": "2024-06-10T14:23:42.718744Z"
    }
   },
   "source": "results['attributions'][background_type].sum(axis=(1,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.70120507e-01,  1.52841201e-02,  9.28617418e-02,  1.13407120e-01,\n",
       "        1.83220327e-01,  2.10560542e-02,  1.27464145e-01,  1.06733963e-01,\n",
       "        1.75181329e-02,  1.57249138e-01,  1.40664607e-01,  1.49215162e-01,\n",
       "        1.59901679e-02,  1.27517417e-01,  1.47278994e-01,  1.60658777e-01,\n",
       "        2.17270672e-01,  5.09824380e-02,  3.32470946e-02,  3.66214737e-02,\n",
       "        1.30641073e-01,  1.23184487e-01,  1.96215227e-01,  1.38463348e-01,\n",
       "        8.75410587e-02,  9.70023274e-02,  1.71967596e-01,  1.50519937e-01,\n",
       "        5.04426882e-02,  1.61408171e-01,  2.16436416e-01,  1.41229391e-01,\n",
       "        1.41947210e-01,  1.62317842e-01,  1.64650887e-01,  1.64535791e-01,\n",
       "        1.46388069e-01,  1.16750002e-01,  1.22873716e-01,  4.31026220e-02,\n",
       "        1.57310590e-01,  1.00012690e-01,  1.55799270e-01,  1.55326679e-01,\n",
       "        8.71996731e-02,  1.57125652e-01,  1.36757612e-01,  3.19495164e-02,\n",
       "        1.55807734e-01,  3.47837806e-02,  9.90368426e-05,  1.06972188e-01,\n",
       "        1.50174171e-01,  1.25235200e-01,  2.20670074e-01,  1.48426294e-01,\n",
       "        5.72129600e-02,  5.23135811e-03,  1.69855252e-01, -9.55441408e-03,\n",
       "        1.81595162e-01,  8.55566040e-02,  1.83773547e-01,  1.74469322e-01,\n",
       "        3.58385742e-02,  1.50771007e-01,  1.02175027e-01,  1.56581402e-03,\n",
       "        7.39983469e-03, -7.07995798e-03,  2.82760896e-02,  2.25948971e-02,\n",
       "        3.39109339e-02,  1.27417088e-01,  9.65246856e-02,  3.17281187e-02,\n",
       "        5.00109047e-03,  1.26921579e-01,  1.34369999e-01,  1.73745632e-01,\n",
       "        1.57104641e-01,  1.37270853e-01,  7.70949945e-02, -4.15297691e-04,\n",
       "        2.89354324e-02,  4.62383078e-03,  1.20482042e-01,  7.14676976e-02,\n",
       "        1.84177309e-01,  1.62069023e-01,  1.86456561e-01,  8.48496482e-02,\n",
       "        2.18016014e-01,  1.39586866e-01,  1.34663373e-01,  1.53521806e-01,\n",
       "        2.53173076e-02,  8.60062540e-02,  1.18714899e-01,  1.63239688e-01,\n",
       "        7.53705502e-02,  1.18462563e-01,  1.14391193e-01,  2.68483628e-02,\n",
       "        2.29834616e-02,  1.15697414e-01,  2.02667177e-01,  6.56441450e-02,\n",
       "        1.53643370e-01,  4.30381391e-03,  5.79964779e-02,  1.98596139e-02,\n",
       "        1.90514505e-01,  9.38736200e-02,  1.25028551e-01,  1.28209993e-01,\n",
       "        1.33996025e-01,  1.38196483e-01,  2.03438237e-01,  1.31943494e-01,\n",
       "        1.49502069e-01,  1.43413126e-01,  1.34794991e-02,  1.24804698e-01,\n",
       "        1.04686841e-01,  7.56240487e-02,  1.34499803e-01,  1.21700674e-01,\n",
       "        6.39081597e-02,  9.29444805e-02,  9.19372439e-02,  2.13646851e-02,\n",
       "        1.33988142e-01,  1.86901391e-01,  1.58457816e-01,  7.32089505e-02,\n",
       "        1.22220784e-01, -1.01578850e-02,  1.59590364e-01,  1.82752252e-01,\n",
       "        1.20933130e-01,  1.36274219e-01,  1.23209335e-01,  5.82058020e-02,\n",
       "        1.32585362e-01,  1.86867490e-02,  1.39303863e-01,  4.07059491e-02,\n",
       "        1.05080873e-01,  9.12766233e-02], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
