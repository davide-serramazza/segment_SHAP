{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:12.836909Z",
     "start_time": "2024-06-11T12:24:10.979943Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import ShapleyValueSampling\n",
    "from tqdm import trange\n",
    "\n",
    "from load_data import load_data\n",
    "from train_models import *\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:12.840376Z",
     "start_time": "2024-06-11T12:24:12.837535Z"
    }
   },
   "source": [
    "# to utils.py\n",
    "\n",
    "def change_points_to_lengths(change_points, array_length):\n",
    "\t# change points is 1D iterable of idxs\n",
    "\t# assumes that each change point is the start of a new segment, aka change_points = start points\n",
    "\tstart_points = np.array(change_points)\n",
    "\tend_points = np.append(change_points[1:], [array_length])\n",
    "\tprint(start_points, end_points)\n",
    "\tlengths = end_points - start_points\n",
    "\treturn lengths\n",
    "\n",
    "def lengths_to_weights(lengths):\n",
    "\t# lengths is 1D iterable of positive ints\n",
    "\tstart_idx = 0\n",
    "\tend_idx = 0\n",
    "\tsegment_weights = 1 / lengths\n",
    "\tweights = np.ones(lengths.sum())\n",
    "\tfor segment_weight, length in zip(segment_weights, lengths):\n",
    "\t\tend_idx += length\n",
    "\t\tweights[start_idx: end_idx] = segment_weight\n",
    "\t\tstart_idx = end_idx\n",
    "\treturn weights\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:13.012160Z",
     "start_time": "2024-06-11T12:24:12.841209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\"\n",
    "\n",
    "# dictionary mapping predictors to torch vs other, necessary for Captum \n",
    "predictors = {\n",
    "\t'torch' : ['resNet'],\n",
    "\t'scikit' : ['miniRocket','randomForest']\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:15.419175Z",
     "start_time": "2024-06-11T12:24:13.012774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data\n",
    "dataset_name = 'gunpoint'\n",
    "predictor_name = 'resNet'\n",
    "\n",
    "# I've returned also a Label encoder from load_data to have a mapping between dataset label\n",
    "# which can be string while captum requires idx (integers)\n",
    "X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "\n",
    "# train model\n",
    "if predictor_name=='resNet':\n",
    "\tclf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device)\n",
    "elif predictor_name=='miniRocket':\n",
    "\tclf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name)\n",
    "\n",
    "# create a dictionary to be dumped containing attribution and metadata\n",
    "# initialize data structure meant to contain the segments\n",
    "segments =  np.empty( (X_test.shape[0] , X_test.shape[1]), dtype=object) if X_test.shape[1] > 1  else (\n",
    "\tnp.empty( X_test.shape[0] , dtype=object))\n",
    "\n",
    "results = {\n",
    "\t'attributions' : {},\n",
    "\t'segments' : segments,\n",
    "\t'y_test_true' : y_test,\n",
    "\t'y_test_pred' : preds,\n",
    "\t'label_mapping' : enc,\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ResNet\n",
      "Epoch 1: train loss:  0.660, \t train accuracy  0.560 \n",
      "          test loss:  0.586,  \t test accuracy  0.780\n",
      "Epoch 11: train loss:  0.246, \t train accuracy  0.980 \n",
      "          test loss:  0.304,  \t test accuracy  0.927\n",
      "Epoch 21: train loss:  0.119, \t train accuracy  1.000 \n",
      "          test loss:  0.151,  \t test accuracy  0.993\n",
      "Epoch 31: train loss:  0.064, \t train accuracy  1.000 \n",
      "          test loss:  0.103,  \t test accuracy  0.993\n",
      "Epoch 41: train loss:  0.044, \t train accuracy  1.000 \n",
      "          test loss:  0.083,  \t test accuracy  0.993\n",
      "Epoch 51: train loss:  0.033, \t train accuracy  1.000 \n",
      "          test loss:  0.070,  \t test accuracy  1.000\n",
      "Epoch 61: train loss:  0.034, \t train accuracy  1.000 \n",
      "          test loss:  0.061,  \t test accuracy  1.000\n",
      "training early stopped! Final stats are:\n",
      "Epoch 65: train loss:  0.026, \t train accuracy  1.000 \n",
      "          test loss:  0.059,  \t test accuracy  1.000\n",
      "accuracy for resNet is  1.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:15.423906Z",
     "start_time": "2024-06-11T12:24:15.420257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_background = 50\n",
    "background_types = [\"average\", \"zero\",\"sampling\"] # zero, constant, average, multisample\n",
    "for type in background_types:\n",
    "\tresults['attributions'][type] = np.zeros( X_test.shape ,dtype=np.float32 )"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:24:15.427405Z",
     "start_time": "2024-06-11T12:24:15.424781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for type in background_types:\n",
    "\tprint( type, np.where( results['attributions'][type] == 0)[0].shape )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average (22500,)\n",
      "zero (22500,)\n",
      "sampling (22500,)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:26:22.489179Z",
     "start_time": "2024-06-11T12:24:15.428433Z"
    }
   },
   "source": [
    "with torch.no_grad():\n",
    "\tSHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "\n",
    "\tfor i in trange ( X_test.shape[0] ) : #\n",
    "\n",
    "\t\t# get current sample and label\n",
    "\t\tts, y = X_test[i] , torch.tensor( y_test[i:i+1] )\n",
    "\n",
    "\t\t# get segment and its tensor representation\n",
    "\t\tcurrent_segments = get_claSP_segmentation(ts)[:X_test.shape[1]]\n",
    "\t\tresults['segments'][i] = current_segments\n",
    "\t\tmask = get_feature_mask(current_segments,ts.shape[-1])\n",
    "\n",
    "\t\tts = torch.tensor(ts).repeat(1,1,1)\n",
    "\n",
    "\t\tfor background_type in background_types:\n",
    "\n",
    "\n",
    "\t\t\t# background data\n",
    "\t\t\tif background_type==\"zero\":\n",
    "\t\t\t\tbackground_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "\t\t\telif background_type==\"sampling\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background)\n",
    "\t\t\telif background_type==\"average\":\n",
    "\t\t\t\tbackground_dataset = sample_background(X_train, n_background).mean(axis=0, keepdim=True)\n",
    "\n",
    "\t\t\tts = ts.repeat(background_dataset.shape[0],1,1) if background_type==\"sampling\" else ts\n",
    "\n",
    "\t\t\t# data structure with room for each sample in the background dataset\n",
    "\t\t\tif predictor_name in predictors['scikit']:\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\t\t\telif predictor_name in predictors['torch']:\n",
    "\t\t\t\tts = ts.to(device); y = y.to(device)\n",
    "\t\t\t\tmask = mask.to(device) ; background_dataset =  background_dataset.to(device)\n",
    "\t\t\t\ttmp = SHAP.attribute( ts, target=y , feature_mask=mask, baselines=background_dataset)\n",
    "\t\t\t\t########  only for random forest as every instance should be a 1D tensor    ########\n",
    "\t\t\t\t#current_attr[j:j+actual_size] = tmp.reshape(actual_size,X_test.shape[1],X_test.shape[2])\n",
    "\t\t\t\t###############################################################################\n",
    "\n",
    "\t\t\t# compute as final explanation mean of each explanation using a different baseline\n",
    "\t\t\tresults['attributions'][background_type][i] = torch.mean(tmp, dim=0).cpu().numpy() if \\\n",
    "\t\t\t\tbackground_type==\"sampling\" else tmp[0].cpu().numpy()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:07<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:26:22.504586Z",
     "start_time": "2024-06-11T12:26:22.490288Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # normalized weights\n",
    "weights = np.array(list(map(lambda x: list(map(lambda y: lengths_to_weights(change_points_to_lengths(y, X_train.shape[-1])), x)), results[\"segments\"])))\n",
    "results[\"attributions\"][background_type] *= weights"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   7  16  47  96 109 118] [  7  16  47  96 109 118 150]\n",
      "[  0  35  45  68  78 101 132] [ 35  45  68  78 101 132 150]\n",
      "[  0  23  47  69 106 119 131] [ 23  47  69 106 119 131 150]\n",
      "[  0  27  61  96 111 119 135] [ 27  61  96 111 119 135 150]\n",
      "[0] [150]\n",
      "[  0   9  19  42  63 112 129] [  9  19  42  63 112 129 150]\n",
      "[ 0 56 64 72 86 99] [ 56  64  72  86  99 150]\n",
      "[  0 123] [123 150]\n",
      "[  0  27  42  80 110 124 141] [ 27  42  80 110 124 141 150]\n",
      "[  0  15  41  57  87 100 132] [ 15  41  57  87 100 132 150]\n",
      "[  0  80  87  99 108 119 137] [ 80  87  99 108 119 137 150]\n",
      "[ 0 10 39 46 63 88 97] [ 10  39  46  63  88  97 150]\n",
      "[  0   9  18  39  77 114 139] [  9  18  39  77 114 139 150]\n",
      "[  0  79  99 131 138] [ 79  99 131 138 150]\n",
      "[  0  15  65  88 103 119 138] [ 15  65  88 103 119 138 150]\n",
      "[ 0 12 83] [ 12  83 150]\n",
      "[  0  34  69 120] [ 34  69 120 150]\n",
      "[ 0  8 19 34 42 77 98] [  8  19  34  42  77  98 150]\n",
      "[0] [150]\n",
      "[  0  33  40  48  65  77 106] [ 33  40  48  65  77 106 150]\n",
      "[  0  26 129] [ 26 129 150]\n",
      "[  0  16  38  70  87  96 115] [ 16  38  70  87  96 115 150]\n",
      "[ 0  7 19] [  7  19 150]\n",
      "[  0  10  40  63  74  88 131] [ 10  40  63  74  88 131 150]\n",
      "[  0  41  50  61  71 128 139] [ 41  50  61  71 128 139 150]\n",
      "[  0  15  24  39  95 111 123] [ 15  24  39  95 111 123 150]\n",
      "[  0  15  47  82 103 124 137] [ 15  47  82 103 124 137 150]\n",
      "[  0  51  83  91  99 109 134] [ 51  83  91  99 109 134 150]\n",
      "[  0  34  42 128 137] [ 34  42 128 137 150]\n",
      "[  0 135] [135 150]\n",
      "[  0  28  45  55  64  76 124] [ 28  45  55  64  76 124 150]\n",
      "[  0  11  86 116 137] [ 11  86 116 137 150]\n",
      "[  0  26  43  51 125] [ 26  43  51 125 150]\n",
      "[  0  68  83  95 108 115 130] [ 68  83  95 108 115 130 150]\n",
      "[  0  11  62  78 128] [ 11  62  78 128 150]\n",
      "[  0  22  45  82 111 121 134] [ 22  45  82 111 121 134 150]\n",
      "[  0  19  34  69  83 110 140] [ 19  34  69  83 110 140 150]\n",
      "[  0 109 124 137] [109 124 137 150]\n",
      "[  0  56 141] [ 56 141 150]\n",
      "[  0   7  17  31  41  62 120] [  7  17  31  41  62 120 150]\n",
      "[  0  36  53  78 109 118 131] [ 36  53  78 109 118 131 150]\n",
      "[  0  18  37  52  66 141] [ 18  37  52  66 141 150]\n",
      "[  0  73  88 101 116 131] [ 73  88 101 116 131 150]\n",
      "[0] [150]\n",
      "[0] [150]\n",
      "[  0  13 100] [ 13 100 150]\n",
      "[ 0 20] [ 20 150]\n",
      "[  0  41  75  89 102 110 119] [ 41  75  89 102 110 119 150]\n",
      "[  0   9  22  40  62 122 133] [  9  22  40  62 122 133 150]\n",
      "[  0  27  71  81 111 126 137] [ 27  71  81 111 126 137 150]\n",
      "[ 0 17 34 44 61 69 79] [ 17  34  44  61  69  79 150]\n",
      "[  0 100] [100 150]\n",
      "[  0  76  86  98 111 118 130] [ 76  86  98 111 118 130 150]\n",
      "[  0  31  41  75  91 110 138] [ 31  41  75  91 110 138 150]\n",
      "[  0  60  71  84  93 107 137] [ 60  71  84  93 107 137 150]\n",
      "[  0  38  60  95 118 128 140] [ 38  60  95 118 128 140 150]\n",
      "[  0  11  23  44 104 119 129] [ 11  23  44 104 119 129 150]\n",
      "[  0  85 131] [ 85 131 150]\n",
      "[  0  19  75  97 107 114 126] [ 19  75  97 107 114 126 150]\n",
      "[  0  32  68  79  97 122 140] [ 32  68  79  97 122 140 150]\n",
      "[  0  14  51 103 117 125 137] [ 14  51 103 117 125 137 150]\n",
      "[  0   9  24  37 133 141] [  9  24  37 133 141 150]\n",
      "[  0  38  49  56  84 117 136] [ 38  49  56  84 117 136 150]\n",
      "[  0  22  31  70  87 123 138] [ 22  31  70  87 123 138 150]\n",
      "[  0 106] [106 150]\n",
      "[ 0  8 75 84] [  8  75  84 150]\n",
      "[  0  13  39  49  68 100 137] [ 13  39  49  68 100 137 150]\n",
      "[  0  66  74  95 105 114 136] [ 66  74  95 105 114 136 150]\n",
      "[  0  27  78  99 119 129] [ 27  78  99 119 129 150]\n",
      "[0] [150]\n",
      "[  0  11  46  69  83 106 125] [ 11  46  69  83 106 125 150]\n",
      "[  0   8  16  36  70 103 122] [  8  16  36  70 103 122 150]\n",
      "[  0  44  67  77 108 122 132] [ 44  67  77 108 122 132 150]\n",
      "[  0  14  37  62  84 107 116] [ 14  37  62  84 107 116 150]\n",
      "[  0  14  30  45  54  91 112] [ 14  30  45  54  91 112 150]\n",
      "[  0  13  34  43  75  86 103] [ 13  34  43  75  86 103 150]\n",
      "[  0  33  62  78  90 104 134] [ 33  62  78  90 104 134 150]\n",
      "[  0  43  57  71  99 119 139] [ 43  57  71  99 119 139 150]\n",
      "[  0  20  34  42  94 131] [ 20  34  42  94 131 150]\n",
      "[  0  28  62 103 125 133 141] [ 28  62 103 125 133 141 150]\n",
      "[  0  32  57  68 104 112 123] [ 32  57  68 104 112 123 150]\n",
      "[ 0  7 19 44 64 83 98] [  7  19  44  64  83  98 150]\n",
      "[  0  21  33  50 128 136] [ 21  33  50 128 136 150]\n",
      "[  0  22  33  46  80 101] [ 22  33  46  80 101 150]\n",
      "[ 0 30 39 75] [ 30  39  75 150]\n",
      "[0] [150]\n",
      "[0] [150]\n",
      "[ 0  9 32 40 48 56 72] [  9  32  40  48  56  72 150]\n",
      "[  0  25  50  70  83 104 134] [ 25  50  70  83 104 134 150]\n",
      "[ 0 23 60 67 80] [ 23  60  67  80 150]\n",
      "[  0  27  41  52  59  72 122] [ 27  41  52  59  72 122 150]\n",
      "[  0  43  88 101 109 120 132] [ 43  88 101 109 120 132 150]\n",
      "[ 0 12 30 72 81] [ 12  30  72  81 150]\n",
      "[  0  11  28  41  65  76 132] [ 11  28  41  65  76 132 150]\n",
      "[0] [150]\n",
      "[  0   7  19  30  75 124 139] [  7  19  30  75 124 139 150]\n",
      "[  0  28  74  82  94 102 135] [ 28  74  82  94 102 135 150]\n",
      "[  0  16  78 101 112 124 137] [ 16  78 101 112 124 137 150]\n",
      "[  0  70  78  94 106 122 140] [ 70  78  94 106 122 140 150]\n",
      "[  0  10  31  55  67 108 139] [ 10  31  55  67 108 139 150]\n",
      "[  0   8  62  77  87 107 120] [  8  62  77  87 107 120 150]\n",
      "[  0  18  63  85 113 126 141] [ 18  63  85 113 126 141 150]\n",
      "[  0  84  96 107 125 139] [ 84  96 107 125 139 150]\n",
      "[  0  87  95 113 132] [ 87  95 113 132 150]\n",
      "[ 0 34 41 54 66] [ 34  41  54  66 150]\n",
      "[  0  25  66 109 117 129 137] [ 25  66 109 117 129 137 150]\n",
      "[  0  65  76 106 119 132] [ 65  76 106 119 132 150]\n",
      "[  0  13  30  99 110 128] [ 13  30  99 110 128 150]\n",
      "[  0   9  25  32  42  67 128] [  9  25  32  42  67 128 150]\n",
      "[  0  15  30  41  66 122] [ 15  30  41  66 122 150]\n",
      "[  0  13  35  77 101 117 141] [ 13  35  77 101 117 141 150]\n",
      "[  0  14 118 137] [ 14 118 137 150]\n",
      "[  0  16  47  67  78  89 138] [ 16  47  67  78  89 138 150]\n",
      "[  0  16  43  62  79  99 126] [ 16  43  62  79  99 126 150]\n",
      "[  0  14  28  43  56  67 111] [ 14  28  43  56  67 111 150]\n",
      "[0] [150]\n",
      "[ 0 15 22 37 69 87 96] [ 15  22  37  69  87  96 150]\n",
      "[  0  34  42  53  81 108] [ 34  42  53  81 108 150]\n",
      "[ 0 19 29] [ 19  29 150]\n",
      "[  0  22  34  49  64  87 104] [ 22  34  49  64  87 104 150]\n",
      "[  0  15  34  45  56  72 125] [ 15  34  45  56  72 125 150]\n",
      "[  0  19  36  69  99 131 141] [ 19  36  69  99 131 141 150]\n",
      "[  0  27  76  84 102 117 137] [ 27  76  84 102 117 137 150]\n",
      "[  0   9 102 109 121 139] [  9 102 109 121 139 150]\n",
      "[  0  19  88 101 117 129] [ 19  88 101 117 129 150]\n",
      "[ 0 25 39 65 82 97] [ 25  39  65  82  97 150]\n",
      "[  0  39  62  79  87 103 119] [ 39  62  79  87 103 119 150]\n",
      "[  0  11  34  54  68  80 139] [ 11  34  54  68  80 139 150]\n",
      "[  0 112 137] [112 137 150]\n",
      "[  0  17  37  56 106 121 137] [ 17  37  56 106 121 137 150]\n",
      "[  0  80  94 107 128 137] [ 80  94 107 128 137 150]\n",
      "[0] [150]\n",
      "[  0  73  84  91 102 117 132] [ 73  84  91 102 117 132 150]\n",
      "[  0  10  19  39  77  93 109] [ 10  19  39  77  93 109 150]\n",
      "[  0  16  42  55  71 109] [ 16  42  55  71 109 150]\n",
      "[  0  23  40  56 117 125 134] [ 23  40  56 117 125 134 150]\n",
      "[ 0 14 38 47 56 85 96] [ 14  38  47  56  85  96 150]\n",
      "[  0  21  42  60  70 128 138] [ 21  42  60  70 128 138 150]\n",
      "[  0   7  50  92 103 111 124] [  7  50  92 103 111 124 150]\n",
      "[  0  74  89  97 110 118 128] [ 74  89  97 110 118 128 150]\n",
      "[0] [150]\n",
      "[  0 111 122 136] [111 122 136 150]\n",
      "[  0  70  79 101] [ 70  79 101 150]\n",
      "[  0  20  31  78  94 125] [ 20  31  78  94 125 150]\n",
      "[  0  72  85 100 112 123 137] [ 72  85 100 112 123 137 150]\n",
      "[  0  37  48  69  76  98 123] [ 37  48  69  76  98 123 150]\n",
      "[  0  57  69  79  98 105 135] [ 57  69  79  98 105 135 150]\n",
      "[  0  13  37  44  77  84 138] [ 13  37  44  77  84 138 150]\n",
      "[  0  19  40  69 101 129] [ 19  40  69 101 129 150]\n",
      "[  0  28  41  49  66 103 115] [ 28  41  49  66 103 115 150]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:26:22.515771Z",
     "start_time": "2024-06-11T12:26:22.505658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dump result to disk\n",
    "file_name = \"_\".join ( (predictor_name,dataset_name) )+\".npy\"\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:26:22.521241Z",
     "start_time": "2024-06-11T12:26:22.516619Z"
    }
   },
   "source": "results['attributions'][background_type].sum(axis=(1,2))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02575701,  0.03623424,  0.08760294,  0.03370653,  0.0713111 ,\n",
       "        0.03288854, -0.01123117, -0.01650581, -0.02834234,  0.02066218,\n",
       "        0.01475134,  0.0148478 ,  0.00777273,  0.04426816,  0.00869553,\n",
       "        0.04137299,  0.01452769, -0.04110344, -0.0564876 , -0.02802648,\n",
       "        0.04746726,  0.03466903,  0.0461098 ,  0.04437881,  0.04852821,\n",
       "        0.05020833,  0.04916243,  0.03219852,  0.00122179,  0.02649945,\n",
       "        0.03616834,  0.07448067,  0.06698915,  0.01906095,  0.06508771,\n",
       "        0.02692945,  0.03860022,  0.02453608,  0.03672948,  0.03263624,\n",
       "        0.00874226,  0.07424445,  0.02614421,  0.02706305,  0.04439206,\n",
       "        0.04847602,  0.03250682,  0.04601926,  0.07049108, -0.0173928 ,\n",
       "       -0.04317379,  0.03355453,  0.03071277,  0.07563438,  0.03310284,\n",
       "        0.04012899,  0.02700376,  0.01058343,  0.03272954,  0.00121123,\n",
       "        0.04281701,  0.08382198,  0.04600122,  0.02108269,  0.02773053,\n",
       "        0.04022697,  0.0385804 ,  0.00674922,  0.05039046,  0.04163282,\n",
       "        0.02098019,  0.03417258,  0.01801425,  0.05184155,  0.04151623,\n",
       "        0.02511019,  0.0414329 ,  0.06393945,  0.06700505,  0.04425632,\n",
       "        0.03597938,  0.02114243,  0.09334677,  0.01628301,  0.0194516 ,\n",
       "        0.04469354,  0.03867382,  0.0526254 ,  0.05325003,  0.02923618,\n",
       "        0.04999886,  0.05124146,  0.04714166,  0.06763553,  0.01523909,\n",
       "        0.03319555,  0.0259183 ,  0.0076413 ,  0.02105495,  0.07078997,\n",
       "       -0.02228574,  0.03859811,  0.0367017 , -0.04658111, -0.03529131,\n",
       "        0.01937565,  0.03433525, -0.0019673 ,  0.05452712,  0.01323167,\n",
       "        0.00924874,  0.01982439,  0.04183301,  0.00612794,  0.03361786,\n",
       "        0.05988785,  0.05408843,  0.03815746,  0.05975427,  0.06993195,\n",
       "        0.04133437,  0.07534732,  0.01871689,  0.09191681,  0.03180439,\n",
       "        0.03181237,  0.03509606,  0.03630786,  0.00556355,  0.0808446 ,\n",
       "        0.04510434,  0.01559157,  0.04011606,  0.04463368,  0.04752684,\n",
       "        0.01778902,  0.01659958, -0.00041518,  0.01907017,  0.04391723,\n",
       "        0.03879773,  0.03723238,  0.02247394,  0.10473265, -0.01278502,\n",
       "        0.04049042,  0.03784461,  0.00913418,  0.03905627,  0.0051077 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
