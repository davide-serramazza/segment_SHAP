{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:31:25.396190Z",
     "start_time": "2024-11-06T12:31:25.371759Z"
    }
   },
   "outputs": [],
   "source": "%reset -f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:01.530138Z",
     "start_time": "2025-01-16T11:53:59.347519Z"
    }
   },
   "source": [
    "from captum.attr import ShapleyValueSampling\n",
    "from load_data import load_data\n",
    "\n",
    "from segmentation import *\n",
    "from utils import *\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "import sys\n",
    "\n",
    "# device for torch\n",
    "from torch.cuda import is_available as is_GPU_available\n",
    "device = \"cuda\" if is_GPU_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:01.535039Z",
     "start_time": "2025-01-16T11:54:01.531250Z"
    }
   },
   "source": [
    "batch_size = 50\n",
    "\n",
    "dataset_names = { 'gunpoint'}    #{sys.argv[1]}\n",
    "predictor_names = {'resNet'}    #{sys.argv[2]} {\"randomForest\", 'miniRocket', 'resNet'}\n",
    "segmentation_names = [ \"equal\", \"clasp\" ,\"greedygaussian\", \"infogain\",\"nnsegment\"]  # {\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"} # {\"clasp\",\"greedygaussian\", \"equal\", \"infogain\",\"nnsegment\"} \n",
    "background_names = { \"zero\", \"average\",\"sampling\"} #{\"average\", \"zero\", \"sampling\"}\n",
    "normalization_names = {\"default\", \"normalized\"}\n",
    "\n",
    "demo_mode = False\n",
    "# demo\n",
    "if demo_mode:\n",
    "    dataset_names = {'UWAVE'}\n",
    "    predictor_names = {\"resNet\"}\n",
    "    segmentation_names = { \"clasp\" ,\"greedygaussian\", \"infogain\",\"nnsegment\", \"equal\"} #,'clasp'}\n",
    "    background_names ={ \"sampling\", \"zero\", \"average\"} #,'sampling'}\n",
    "    normalization_names = {\"default\", \"normalized\"}\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate dictionaries used in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:01.538959Z",
     "start_time": "2025-01-16T11:54:01.536183Z"
    }
   },
   "source": [
    "# dictionary mapping predictors to torch vs other, step necessary for Captum \n",
    "predictors = {\n",
    "    'torch' : ['resNet'],\n",
    "    'scikit' : ['miniRocket','randomForest','QUANT']\n",
    "}\n",
    "segmentation_dict = {\"clasp\":get_claSP_segmentation, \"infogain\": get_InformationGain_segmentation, \"greedygaussian\": get_GreedyGaussian_segmentation, \"equal\": get_equal_segmentation, \"nnsegment\": get_NNSegment_segmentation}\n",
    "\n",
    "results = dict.fromkeys(('y_test_true', 'label_mapping', \"segments\", 'y_test_pred', \"attributions\"))\n",
    "for key in results.keys():\n",
    "    results[key] = dict.fromkeys(dataset_names)\n",
    "    \n",
    "normalization_names = normalization_names | {\"default\"}\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.250394Z",
     "start_time": "2025-01-16T11:54:01.539726Z"
    }
   },
   "source": [
    "from models.predictor_utils import load_predictor, predict_proba\n",
    "from models.train_models import *\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    # init dataset and update the dict to be dumped\n",
    "    X_train, X_test, y_train, y_test, enc = load_data(subset='all', dataset_name=dataset_name)\n",
    "    results['y_test_true'][dataset_name] = y_test ; results['label_mapping'][dataset_name] = enc\n",
    "    for k in [\"attributions\", \"segments\", \"y_test_pred\"] :\n",
    "        results[k][dataset_name] =  dict.fromkeys(segmentation_names)\n",
    "        \n",
    "    # for debugging only\n",
    "    if demo_mode:\n",
    "        X_test = X_test[:2]\n",
    "        y_test = y_test[:2]\n",
    "\n",
    "    # TODO not to save if in demo mode!\n",
    "    for predictor_name in predictor_names:\n",
    "\n",
    "        if predictor_name=='resNet':\n",
    "            clf = load_predictor(\"trained_models\",predictor_name=predictor_name,dataset_name=dataset_name)\n",
    "            preds = predict_proba(clf=clf,samples=X_test)\n",
    "            #clf,preds = train_ResNet(X_train, y_train, X_test, y_test, dataset_name,device=device, dir_name=\"trained_models\")\n",
    "        elif predictor_name=='miniRocket':\n",
    "            #clf,preds = train_miniRocket(X_train, y_train, X_test, y_test, dataset_name, dir_name=\"trained_models\")\n",
    "            clf = load_predictor(\"trained_models\",predictor_name=predictor_name,dataset_name=dataset_name)\n",
    "            preds = predict_proba(clf=clf,samples=X_test)\n",
    "        elif predictor_name==\"randomForest\":\n",
    "            clf = load_predictor(\"trained_models\",predictor_name=predictor_name,dataset_name=dataset_name)\n",
    "            preds = predict_proba(clf=clf,samples=X_test)\n",
    "            #clf, preds = train_randomForest(X_train, y_train, X_test, y_test, dataset_name, dir_name=\"trained_models\")\n",
    "        elif predictor_name==\"QUANT\":\n",
    "            #clf, preds = train_QUANT(X_train, y_train, X_test, y_test, dataset_name, dir_name=\"trained_models\")\n",
    "            clf = load_predictor(\"trained_models\",predictor_name=predictor_name,dataset_name=dataset_name)\n",
    "            preds = predict_proba(clf=clf,samples=X_test)\n",
    "        else:\n",
    "            raise ValueError(\"predictor not found\")\n",
    "\n",
    "        results['y_test_pred'][dataset_name][predictor_name] = preds\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.253987Z",
     "start_time": "2025-01-16T11:54:02.251427Z"
    }
   },
   "source": [
    "def initialize_result_dict(X_test,predictor_names,dataset_name,segmentation_name,results):\n",
    "    \n",
    "    init_segments = np.empty((X_test.shape[0], X_test.shape[1]), dtype=object) if X_test.shape[1] > 1 else ( np.empty(X_test.shape[0], dtype=object))\n",
    "    results[\"segments\"][dataset_name][segmentation_name] = init_segments.copy()\n",
    "    results[\"attributions\"][dataset_name][segmentation_name] = dict.fromkeys(predictor_names)\n",
    "    for predictor_name in predictor_names:\n",
    "        results[\"attributions\"][dataset_name][segmentation_name][predictor_name] = dict.fromkeys(background_names)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.265404Z",
     "start_time": "2025-01-16T11:54:02.254506Z"
    }
   },
   "source": [
    "def get_sample_info(segmentation_method, mask_list, ts_list, y_list, sample ,n_cps):\n",
    "    \n",
    "    # get current sample and label\n",
    "    x, y = sample[0]  , torch.tensor((sample[1]))\n",
    "    ts = torch.tensor(x)\n",
    "    # get segment and its tensor representation\n",
    "    current_segments = segmentation_method(x[0] , n_segments= n_cps)[:X_test.shape[1]]\n",
    "    mask = get_feature_mask(current_segments, ts.shape[-1])\n",
    "    \n",
    "    # append any relevant information into the correct list\n",
    "    mask_list.append(mask)\n",
    "    ts_list.append(ts)\n",
    "    y_list.append(y)\n",
    "    \n",
    "    return ts,y,mask, current_segments\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.268562Z",
     "start_time": "2025-01-16T11:54:02.266097Z"
    }
   },
   "source": [
    "from utils import sample_background\n",
    "\n",
    "def get_background( background_name, X_train, n_background=50):\n",
    "\n",
    "    # background data\n",
    "    if background_name == \"zero\":\n",
    "        background_dataset = torch.zeros((1,) + X_train.shape[1:])\n",
    "    elif background_name == \"sampling\":\n",
    "        background_dataset = sample_background(X_train, n_background)\n",
    "    elif background_name == \"average\":\n",
    "        background_dataset = torch.Tensor( X_train.mean(axis=0, keepdims=True) )\n",
    "\n",
    "    return background_dataset\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.272282Z",
     "start_time": "2025-01-16T11:54:02.269316Z"
    }
   },
   "source": [
    "def get_attribution(explainer, ts, mask, background_dataset,y, sampling ): \n",
    "    \n",
    "    if sampling:\n",
    "        # get rid of first dimension as it's always 1\n",
    "        # TODO try to flatten multiple singles \"50 samples\" into a 3D dataset and get the performances of that\n",
    "        ts = ts[0] ;  mask= mask[0] ; y=y[0]\n",
    "\n",
    "    if predictor_name in predictors['scikit']:\n",
    "        \n",
    "        tmp = explainer.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset, additional_forward_args=clf)\n",
    "\n",
    "    elif predictor_name in predictors['torch']:\n",
    "        # if use torch make sure everything is on selected device\n",
    "        ts = ts.to(device); y = y.to(device) ; mask = mask.to(device); background_dataset = background_dataset.to(device)\n",
    "        tmp = explainer.attribute(ts, target=y, feature_mask=mask, baselines=background_dataset)\n",
    "\n",
    "    # in case of random forest 'un-flatten' result\n",
    "    if predictor_name==\"randomForest\":\n",
    "        tmp = tmp.reshape(-1,X_test.shape[1],X_test.shape[2])\n",
    "\n",
    "    # lastly store current explanation in the data structure; if sampling store the mean\n",
    "    saliency_map = torch.mean(tmp, dim=0,  keepdim=True).cpu().numpy() if sampling else tmp.cpu().numpy()\n",
    "    return saliency_map\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.275136Z",
     "start_time": "2025-01-16T11:54:02.272756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def store_results(table, segmentation_name, normalization_names, current_results, start):\n",
    "    \n",
    "    # store \"default\" result\n",
    "    n_results = current_results.shape[0]\n",
    "    if 'default' in normalization_names:\n",
    "        table['default'][start: (start+n_results) ] = current_results\n",
    "\n",
    "    \n",
    "    # and normalized result\n",
    "    if \"normalized\" in normalization_names:\n",
    "        weights = np.array(list(map(\n",
    "            lambda segmentation: list(map(\n",
    "                lambda channel_segemnts: lengths_to_weights(change_points_to_lengths(channel_segemnts, X_train.shape[-1])),\n",
    "                segmentation)),\n",
    "            results[\"segments\"][dataset_name][segmentation_name][start: (start+n_results) ]  )))\n",
    "        \n",
    "        table['normalized'][start: (start+n_results) ]  = current_results * weights\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ideal n_cps to be found"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:02.277180Z",
     "start_time": "2025-01-16T11:54:02.275608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define number of cps to look for each dataset\n",
    "\n",
    "ideal_n_cps = {\n",
    "    \"gunpoint\" : 3,\n",
    "    \"UWAVE\" : 7,\n",
    "    \"EOG\" : 5 ,\n",
    "    \"MP8\" : 8 ,\n",
    "    \"KeplerLightCurves\" : 15,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# explain"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:54:17.486898Z",
     "start_time": "2025-01-16T11:54:02.973783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.SHAP_dataloader import SHAP_dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "starttime = timeit.default_timer()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dataset_name in dataset_names:\n",
    "        \n",
    "        for segmentation_name in segmentation_names:\n",
    "            \n",
    "            # initialize part of the dictionary and lists to be used\n",
    "            initialize_result_dict(X_test,predictor_names,dataset_name,segmentation_name,results)\n",
    "            segmentation_method = segmentation_dict[segmentation_name]\n",
    "            \n",
    "            ts_list = [] ; mask_list = [] ; y_list = []\n",
    "            n_samples, n_chs, ts_length = X_test.shape\n",
    "\n",
    "            # first run segmentation\n",
    "            for i in range(n_samples) : \n",
    "                ts,y,mask, current_segment = get_sample_info( segmentation_method, mask_list, ts_list, y_list , sample=( X_test[i:i+1], y_test[i:i + 1]) ,n_cps = ideal_n_cps[dataset_name]  )\n",
    "                results['segments'][dataset_name][segmentation_name][i] = current_segment\n",
    "\n",
    "            for background_name in background_names:\n",
    "\n",
    "                # get the background for the current data\n",
    "                results[\"attributions\"][dataset_name][segmentation_name][predictor_name][background_name] = dict.fromkeys(normalization_names)\n",
    "                background_dataset = get_background( background_name, X_train)\n",
    "                \n",
    "\n",
    "                for predictor_name in predictor_names:\n",
    "                    # get classifier and initialize attributions\n",
    "                    init_attributions = np.zeros(X_test.shape, dtype=np.float32)\n",
    "                    for normalization_name in normalization_names:\n",
    "                        results['attributions'][dataset_name][segmentation_name][predictor_name][background_name][normalization_name] = init_attributions.copy()\n",
    "\n",
    "                    # instantiate SHAP explainer                    \n",
    "                    SHAP = ShapleyValueSampling(clf) if predictor_name in predictors['torch'] else ShapleyValueSampling(forward_classification)\n",
    "                    \n",
    "                    # prepare for batch computation\n",
    "                    data_loader = DataLoader( SHAP_dataloader(ts_list,y_list,mask_list, background_dim=background_dataset.shape[0] ) ,\n",
    "                        batch_size= 1 if background_name=='sampling' else batch_size)\n",
    "                    \n",
    "                    # computation loop\n",
    "                    current_idx = 0\n",
    "                    with tqdm(total=len(ts_list)) as pbar:\n",
    "                        for (ts,y,mask) in data_loader:\n",
    "        \n",
    "                            current_results = get_attribution( SHAP, ts,mask,background_dataset,y, \n",
    "                                    sampling= (background_name=='sampling') )\n",
    "                            \n",
    "                            store_results(table=results['attributions'][dataset_name][segmentation_name][predictor_name][background_name], segmentation_name =segmentation_name, normalization_names=normalization_names,current_results=current_results, start=current_idx)\n",
    "                            \n",
    "                            # update counters\n",
    "                            pbar.update(current_results.shape[0])  ; current_idx+=current_results.shape[0]\n",
    "                            sys.stderr.flush() ; sys.stdout.flush()\n",
    "                            \n",
    "                    pbar.close()\n",
    "                    \n",
    "print(\"elapsed time\", ( timeit.default_timer() -starttime ) )\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:02<00:00, 73.11it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 75.26it/s]\n",
      " 10%|█         | 15/150 [00:10<01:30,  1.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 48\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(ts_list)) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (ts,y,mask) \u001B[38;5;129;01min\u001B[39;00m data_loader:\n\u001B[0;32m---> 48\u001B[0m         current_results \u001B[38;5;241m=\u001B[39m get_attribution( SHAP, ts,mask,background_dataset,y, \n\u001B[1;32m     49\u001B[0m                 sampling\u001B[38;5;241m=\u001B[39m (background_name\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msampling\u001B[39m\u001B[38;5;124m'\u001B[39m) )\n\u001B[1;32m     51\u001B[0m         store_results(table\u001B[38;5;241m=\u001B[39mresults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattributions\u001B[39m\u001B[38;5;124m'\u001B[39m][dataset_name][segmentation_name][predictor_name][background_name], segmentation_name \u001B[38;5;241m=\u001B[39msegmentation_name, normalization_names\u001B[38;5;241m=\u001B[39mnormalization_names,current_results\u001B[38;5;241m=\u001B[39mcurrent_results, start\u001B[38;5;241m=\u001B[39mcurrent_idx)\n\u001B[1;32m     53\u001B[0m         \u001B[38;5;66;03m# update counters\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[8], line 15\u001B[0m, in \u001B[0;36mget_attribution\u001B[0;34m(explainer, ts, mask, background_dataset, y, sampling)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m predictor_name \u001B[38;5;129;01min\u001B[39;00m predictors[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# if use torch make sure everything is on selected device\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     ts \u001B[38;5;241m=\u001B[39m ts\u001B[38;5;241m.\u001B[39mto(device); y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(device) ; mask \u001B[38;5;241m=\u001B[39m mask\u001B[38;5;241m.\u001B[39mto(device); background_dataset \u001B[38;5;241m=\u001B[39m background_dataset\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 15\u001B[0m     tmp \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mattribute(ts, target\u001B[38;5;241m=\u001B[39my, feature_mask\u001B[38;5;241m=\u001B[39mmask, baselines\u001B[38;5;241m=\u001B[39mbackground_dataset)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# in case of random forest 'un-flatten' result\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m predictor_name\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandomForest\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/log/__init__.py:42\u001B[0m, in \u001B[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:376\u001B[0m, in \u001B[0;36mShapleyValueSampling.attribute\u001B[0;34m(self, inputs, baselines, target, additional_forward_args, feature_mask, n_samples, perturbations_per_eval, show_progress)\u001B[0m\n\u001B[1;32m    361\u001B[0m prev_results \u001B[38;5;241m=\u001B[39m initial_eval\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[1;32m    363\u001B[0m     current_inputs,\n\u001B[1;32m    364\u001B[0m     current_add_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    374\u001B[0m     perturbations_per_eval,\n\u001B[1;32m    375\u001B[0m ):\n\u001B[0;32m--> 376\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28msum\u001B[39m(torch\u001B[38;5;241m.\u001B[39msum(mask)\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m mask \u001B[38;5;129;01min\u001B[39;00m current_masks) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    377\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    378\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature mask is missing some integers between 0 and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    379\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_features, for optimal performance, make sure each\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    380\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m consecutive integer corresponds to a feature.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    381\u001B[0m         )\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;66;03m# modified_eval dimensions: 1D tensor with length\u001B[39;00m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;66;03m# equal to #num_examples * #features in batch\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/segment_shap/lib/python3.11/site-packages/captum/attr/_core/shapley_value.py:376\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    361\u001B[0m prev_results \u001B[38;5;241m=\u001B[39m initial_eval\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[1;32m    363\u001B[0m     current_inputs,\n\u001B[1;32m    364\u001B[0m     current_add_args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    374\u001B[0m     perturbations_per_eval,\n\u001B[1;32m    375\u001B[0m ):\n\u001B[0;32m--> 376\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28msum\u001B[39m(torch\u001B[38;5;241m.\u001B[39msum(mask)\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m mask \u001B[38;5;129;01min\u001B[39;00m current_masks) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    377\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    378\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature mask is missing some integers between 0 and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    379\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_features, for optimal performance, make sure each\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    380\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m consecutive integer corresponds to a feature.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    381\u001B[0m         )\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;66;03m# modified_eval dimensions: 1D tensor with length\u001B[39;00m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;66;03m# equal to #num_examples * #features in batch\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ideal n_cps to be found"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:36:55.687694Z",
     "start_time": "2025-01-16T11:36:55.684134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ideal_n_cps = {\n",
    "    \"gunpoint\" : 3,\n",
    "    \"UWAVE\" : 7 ,\n",
    "    \"EOG\" : 5,\n",
    "    \"MP8\" : 8,\n",
    "    \"KeplerLightCurves\" : 15\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:36:56.039769Z",
     "start_time": "2025-01-16T11:36:56.035038Z"
    }
   },
   "source": [
    "# dump result to disk\n",
    "if not demo_mode:\n",
    "    file_name = \"_\".join( (\"all_results\",dataset_name,predictor_name) )\n",
    "else:\n",
    "\tfile_name = \"_\".join( (\"all_results_DEMO_\",dataset_name,predictor_name) )\n",
    "file_path = os.path.join(\"attributions\", file_name)\n",
    "np.save( file_path, results )"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment_shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
